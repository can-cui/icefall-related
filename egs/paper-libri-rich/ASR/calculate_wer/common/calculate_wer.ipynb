{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# model_silero_te, example_texts, languages, punct, apply_te = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "#                                                                   model='silero_te')\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize,TreebankWordTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/ccui/.cache/torch/hub/snakers4_silero-models_master\n"
     ]
    }
   ],
   "source": [
    "import soundfile\n",
    "\n",
    "# load model and processor\n",
    "import os\n",
    "\n",
    "# import librosa\n",
    "import jiwer\n",
    "import string\n",
    "import csv\n",
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller()\n",
    "from transformers import pipeline\n",
    "\n",
    "# fix_spelling = pipeline(\"text2text-generation\",model=\"oliverguhr/spelling-correction-english-base\")\n",
    "model_silero_te, example_texts, languages, punct, apply_te = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                                                  model='silero_te') # Light\n",
    "\n",
    "def get_gold_hyp_lists(gold_path, test_path, septype):\n",
    "    def create_hyp_sentence_dictionary(filename):\n",
    "        sentence_dict = {}\n",
    "        with open(filename, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for idx, line in enumerate(lines):\n",
    "                line = line.strip()\n",
    "                if line and len(line.split(septype, 1)) == 2:\n",
    "                    # print(line.split(septype, 1))\n",
    "                    sentence_id, sentence = line.split(septype, 1)\n",
    "                    # sentence_id=sentence_id+\".wav\" # for AMI\n",
    "                    sentence_id = sentence_id.split(\".\", 1)[0]  # cv\n",
    "                    lm_out = apply_te(sentence.lower(), lan=\"en\")\n",
    "                    sentence_dict[sentence_id] = lm_out\n",
    "        return sentence_dict\n",
    "\n",
    "    def create_gold_sentence_dictionary(filename):\n",
    "        sentence_dict = {}\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                # parts = line.split(' ', 1) # Libri\n",
    "                parts = line.split(\",\", 1)  # AMI\n",
    "                sentence_id, sentence = parts\n",
    "                # print(sentence_id)\n",
    "                # sentence_id = sentence_id.split(\"/\", 1)[1]  # AMI\n",
    "                sentence_id = sentence_id.split(\".\", 1)[0]  # cv\n",
    "                # print(sentence_id)\n",
    "                # print(sentence.strip())\n",
    "                if sentence.strip() != \"\":\n",
    "                    sentence_dict[sentence_id] = sentence.strip()\n",
    "        return sentence_dict\n",
    "\n",
    "    def read_csv_to_dict(file_path):\n",
    "        result_dict = {}\n",
    "        with open(file_path, \"r\") as csvfile:\n",
    "            csv_reader = csv.reader(csvfile)\n",
    "            for row in csv_reader:\n",
    "                key, value = row[0], row[1]\n",
    "                key = key.split(\"/\")[1]\n",
    "                # print(key,value)\n",
    "                # break\n",
    "                result_dict[key] = value\n",
    "        return result_dict\n",
    "\n",
    "    gold_dict = create_gold_sentence_dictionary(gold_path)\n",
    "    # gold_dict = read_csv_to_dict(gold_path)\n",
    "    test_dict = create_hyp_sentence_dictionary(test_path)\n",
    "\n",
    "    gold_list = []\n",
    "    test_list = []\n",
    "    for test_key, test_value in test_dict.items():\n",
    "        # print(test_key)\n",
    "        if test_key in gold_dict:\n",
    "            gold = gold_dict[test_key]\n",
    "            gold_list.append(gold)\n",
    "            test_list.append(test_value)\n",
    "    print(len(test_list))\n",
    "    return gold_list, test_list\n",
    "\n",
    "\n",
    "def add_space_before_punctuation(text):\n",
    "    # List of punctuation marks\n",
    "    punctuation_marks = string.punctuation\n",
    "\n",
    "    # Iterate over each character in the text\n",
    "    modified_text = \"\"\n",
    "    for char in text:\n",
    "        if char in punctuation_marks:\n",
    "            modified_text += \" \" + char\n",
    "        else:\n",
    "            modified_text += char\n",
    "\n",
    "    return modified_text\n",
    "\n",
    "\n",
    "def add_space_before_punctuation(text):\n",
    "    # List of punctuation marks\n",
    "    punctuation_marks = string.punctuation\n",
    "\n",
    "    # Iterate over each character in the text\n",
    "    modified_text = \"\"\n",
    "    for char in text:\n",
    "        if char in punctuation_marks:\n",
    "            modified_text += \" \" + char\n",
    "        else:\n",
    "            modified_text += char\n",
    "\n",
    "    return modified_text\n",
    "\n",
    "\n",
    "def add_space(reference_list, hypothesis_list):\n",
    "    reference = []\n",
    "    hypothesis = []\n",
    "    for ref, hyp in zip(reference_list, hypothesis_list):\n",
    "        # Preprocess sentences to keep punctuation as separate words\n",
    "        reference.append(add_space_before_punctuation(ref))\n",
    "        hypothesis.append(add_space_before_punctuation(hyp))\n",
    "        # print(reference,hypothesis)\n",
    "        # Calculate WER\n",
    "\n",
    "    #     wer = jiwer.wer(reference, hypothesis)\n",
    "    #     # print(wer)\n",
    "    #     wer_scores.append(wer)\n",
    "    # wer_mean=sum(wer_scores) / len(wer_scores)\n",
    "\n",
    "    return reference, hypothesis\n",
    "\n",
    "\n",
    "def get_detail_wer(gold_list, test_list):\n",
    "    out = jiwer.process_words(\n",
    "        gold_list,\n",
    "        test_list,\n",
    "    )\n",
    "    print(\"wer: \", out.wer * 100)\n",
    "    print(\"hits: \", out.hits)\n",
    "    print(\"substitutions: \", out.substitutions)\n",
    "    print(\"insertions: \", out.insertions)\n",
    "    print(\"deletions: \", out.deletions)\n",
    "    print(\"total words: \", out.hits + out.substitutions + out.deletions)\n",
    "\n",
    "\n",
    "# def get_t_p_wer(substitutions, insertions,deletions,total_words_punc, P_WER):\n",
    "#     t_p_wer=(substitutions+insertions+deletions)/total_words_punc\n",
    "#     print(\"Topline of P-WER is \",t_p_wer*100)\n",
    "#     print(\"Relative PER is \", P_WER-t_p_wer*100)\n",
    "\n",
    "\n",
    "def get_c_p_er_fr_wer(wer, C_WER, P_WER, clean=True):\n",
    "    if clean:\n",
    "        total_words = 50082\n",
    "        total_words_punt = 57312\n",
    "        cased_words = 3849\n",
    "        p_num = 9709\n",
    "    else:\n",
    "        total_words = 48488\n",
    "        total_words_punt = 55896\n",
    "        cased_words = 4231\n",
    "        p_num = 9408\n",
    "    error_words = wer * total_words\n",
    "    error_c = C_WER * total_words\n",
    "    cer = (error_c - error_words) / cased_words\n",
    "    error_p = P_WER * total_words_punt\n",
    "    per = (error_p - error_words) / p_num\n",
    "    # print(\"Topline of P-WER is \",t_p_wer)\n",
    "    print(\"Relative CER is \", cer)\n",
    "    print(\"Relative PER is \", per)\n",
    "\n",
    "\n",
    "def get_c_p_er_fr_wer_ami(wer, C_WER, P_WER):\n",
    "    # if clean:\n",
    "    total_words = 94006\n",
    "    total_words_punt = 110266\n",
    "    cased_words = 7626\n",
    "    p_num = 16260\n",
    "    error_words = wer * total_words\n",
    "    error_c = C_WER * total_words\n",
    "    cer = (error_c - error_words) / cased_words\n",
    "    error_p = P_WER * total_words_punt\n",
    "    per = (error_p - error_words) / p_num\n",
    "    print(\"Relative CER is \", cer)\n",
    "    print(\"Relative PER is \", per)\n",
    "\n",
    "\n",
    "def get_c_p_er_fr_wer_cv(wer, C_WER, P_WER):\n",
    "    # if clean:\n",
    "    total_words = 11244\n",
    "    total_words_punt = 13146\n",
    "    cased_words = 1882\n",
    "    p_num = 1902\n",
    "    error_words = wer * total_words\n",
    "    error_c = C_WER * total_words\n",
    "    cer = (error_c - error_words) / cased_words\n",
    "    error_p = P_WER * total_words_punt\n",
    "    per = (error_p - error_words) / p_num\n",
    "    print(\"Relative CER is \", cer)\n",
    "    print(\"Relative PER is \", per)\n",
    "\n",
    "\n",
    "def get_cased_word(text_list):\n",
    "    capitalized_word_count = 0\n",
    "\n",
    "    # Iterate through the list of text\n",
    "    for text in text_list:\n",
    "        # Split the text into words\n",
    "        words = text.split()\n",
    "\n",
    "        # Check each word in the text\n",
    "        for word in words:\n",
    "            # Check if the word is capitalized (first character is uppercase)\n",
    "            if word.isalpha() and word[0].isupper():\n",
    "                capitalized_word_count += 1\n",
    "    print(\"Cased words number is \", capitalized_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_list, test_list = get_gold_hyp_lists(\n",
    "    \"/Users/ccui/Desktop/POC/dictation/CommonVoice/cv-en_test-2k_len4-10.txt\",\n",
    "    \"cv-40.txt\",\n",
    "    \",\",\n",
    ")\n",
    "get_cased_word(gold_list)\n",
    "gold_list, test_list = add_space(gold_list, test_list)\n",
    "print(\"CP-WER\")\n",
    "total_wer = get_detail_wer(gold_list, test_list)\n",
    "gold_rc = jiwer.ToLowerCase()(gold_list)\n",
    "test_rc = jiwer.ToLowerCase()(test_list)\n",
    "print(\"P-WER\")\n",
    "wer_rc = get_detail_wer(gold_rc, test_rc)\n",
    "# print(\"WER removing case:\", wer_rc*100)\n",
    "gold_rp = jiwer.RemovePunctuation()(gold_list)\n",
    "test_rp = jiwer.RemovePunctuation()(test_list)\n",
    "# gold_rp,test_rp= add_space(gold_rp,test_rp)\n",
    "print(\"C-WER\")\n",
    "wer_rp = get_detail_wer(gold_rp, test_rp)\n",
    "# print(\"WER removing punctuation:\", wer_rp*100)\n",
    "gold_rc_rp = jiwer.RemovePunctuation()(gold_rc)\n",
    "test_rc_rp = jiwer.RemovePunctuation()(test_rc)\n",
    "wer_rc_rp = get_detail_wer(gold_rc_rp, test_rc_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2491\n",
      "CP-WER\n",
      "wer:  11.706840618132347\n",
      "hits:  51117\n",
      "substitutions:  3669\n",
      "insertions:  495\n",
      "deletions:  2548\n",
      "total words:  57334\n",
      "P-WER\n",
      "wer:  9.423727631074057\n",
      "hits:  52433\n",
      "substitutions:  2346\n",
      "insertions:  502\n",
      "deletions:  2555\n",
      "total words:  57334\n",
      "C-WER\n",
      "wer:  4.926147704590819\n",
      "hits:  47752\n",
      "substitutions:  2230\n",
      "insertions:  120\n",
      "deletions:  118\n",
      "total words:  50100\n",
      "wer:  2.189620758483034\n",
      "hits:  49123\n",
      "substitutions:  859\n",
      "insertions:  120\n",
      "deletions:  118\n",
      "total words:  50100\n"
     ]
    }
   ],
   "source": [
    "gold_list,test_list = get_gold_hyp_lists(\"/Users/ccui/Desktop/dictation/books-transcription/test-clean-rich-book.txt\",\"clean_casePunc.txt\",',')\n",
    "# get_cased_word(gold_list)\n",
    "gold_list,test_list= add_space(gold_list,test_list)\n",
    "print(\"CP-WER\")\n",
    "total_wer = get_detail_wer(gold_list, test_list)\n",
    "gold_rc= jiwer.ToLowerCase()(gold_list)\n",
    "test_rc = jiwer.ToLowerCase()(test_list)\n",
    "print(\"P-WER\")\n",
    "wer_rc = get_detail_wer(gold_rc, test_rc)\n",
    "# print(\"WER removing case:\", wer_rc*100)\n",
    "gold_rp= jiwer.RemovePunctuation()(gold_list)\n",
    "test_rp = jiwer.RemovePunctuation()(test_list)\n",
    "# gold_rp,test_rp= add_space(gold_rp,test_rp)\n",
    "print(\"C-WER\")\n",
    "wer_rp = get_detail_wer(gold_rp, test_rp)\n",
    "# print(\"WER removing punctuation:\", wer_rp*100)\n",
    "gold_rc_rp= jiwer.RemovePunctuation()(gold_rc)\n",
    "test_rc_rp = jiwer.RemovePunctuation()(test_rc)\n",
    "wer_rc_rp = get_detail_wer(gold_rc_rp, test_rc_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative CER is  35.606843989340106\n",
      "Relative PER is  44.33330839074766\n"
     ]
    }
   ],
   "source": [
    "get_c_p_er_fr_wer(wer=2.189620758483034,C_WER=4.926147704590819,P_WER=9.423727631074057,clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2731\n",
      "CP-WER\n",
      "wer:  14.913896389549544\n",
      "hits:  48195\n",
      "substitutions:  5018\n",
      "insertions:  614\n",
      "deletions:  2708\n",
      "total words:  55921\n",
      "P-WER\n",
      "wer:  12.39605872570233\n",
      "hits:  49617\n",
      "substitutions:  3582\n",
      "insertions:  628\n",
      "deletions:  2722\n",
      "total words:  55921\n",
      "C-WER\n",
      "wer:  8.075123178098007\n",
      "hits:  44820\n",
      "substitutions:  3423\n",
      "insertions:  230\n",
      "deletions:  264\n",
      "total words:  48507\n",
      "WER\n",
      "wer:  5.036386500917393\n",
      "hits:  46296\n",
      "substitutions:  1945\n",
      "insertions:  232\n",
      "deletions:  266\n",
      "total words:  48507\n"
     ]
    }
   ],
   "source": [
    "gold_list,test_list = get_gold_hyp_lists(\"/Users/ccui/Desktop/dictation/books-transcription/test-other-rich-book.txt\",\"other_casePunc.txt\",',')\n",
    "# get_cased_word(gold_list)\n",
    "gold_list,test_list= add_space(gold_list,test_list)\n",
    "print(\"CP-WER\")\n",
    "total_wer = get_detail_wer(gold_list, test_list)\n",
    "# print(\"Total WER:\", total_wer*100)\n",
    "gold_rc= jiwer.ToLowerCase()(gold_list)\n",
    "test_rc = jiwer.ToLowerCase()(test_list)\n",
    "print(\"P-WER\")\n",
    "wer_rc = get_detail_wer(gold_rc, test_rc)\n",
    "# print(\"WER removing case:\", wer_rc*100)\n",
    "gold_rp= jiwer.RemovePunctuation()(gold_list)\n",
    "test_rp = jiwer.RemovePunctuation()(test_list)\n",
    "# gold_rp,test_rp= add_space(gold_rp,test_rp)\n",
    "print(\"C-WER\")\n",
    "wer_rp = get_detail_wer(gold_rp, test_rp)\n",
    "# print(\"WER removing punctuation:\", wer_rp*100)\n",
    "gold_rc_rp= jiwer.RemovePunctuation()(gold_rc)\n",
    "test_rc_rp = jiwer.RemovePunctuation()(test_rc)\n",
    "print(\"WER\")\n",
    "wer_rc_rp = get_detail_wer(gold_rc_rp, test_rc_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative CER is  34.82445379417008\n",
      "Relative PER is  47.691941951039006\n"
     ]
    }
   ],
   "source": [
    "get_c_p_er_fr_wer(wer=5.036386500917393,C_WER=8.075123178098007,P_WER=12.39605872570233,clean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9474\n",
      "CP-WER\n",
      "wer:  45.9960459253079\n",
      "hits:  63081\n",
      "substitutions:  26610\n",
      "insertions:  3533\n",
      "deletions:  20575\n",
      "total words:  110266\n",
      "P-WER\n",
      "wer:  42.97698293218218\n",
      "hits:  66524\n",
      "substitutions:  23053\n",
      "insertions:  3647\n",
      "deletions:  20689\n",
      "total words:  110266\n",
      "C-WER\n",
      "wer:  41.19098780928877\n",
      "hits:  57268\n",
      "substitutions:  22073\n",
      "insertions:  1984\n",
      "deletions:  14665\n",
      "total words:  94006\n",
      "wer:  37.465693679126865\n",
      "hits:  60823\n",
      "substitutions:  18465\n",
      "insertions:  2037\n",
      "deletions:  14718\n",
      "total words:  94006\n"
     ]
    }
   ],
   "source": [
    "gold_list,test_list = get_gold_hyp_lists(\"/Users/ccui/Desktop/dictation/vasr/calculate_wer/ami_test_gold_process.txt\",\"ihm_casePunc.txt\",',')\n",
    "# get_cased_word(gold_list)\n",
    "gold_list,test_list= add_space(gold_list,test_list)\n",
    "print(\"CP-WER\")\n",
    "total_wer = get_detail_wer(gold_list, test_list)\n",
    "# print(\"Total WER:\", total_wer*100)\n",
    "gold_rc= jiwer.ToLowerCase()(gold_list)\n",
    "test_rc = jiwer.ToLowerCase()(test_list)\n",
    "print(\"P-WER\")\n",
    "wer_rc = get_detail_wer(gold_rc, test_rc)\n",
    "# print(\"WER removing case:\", wer_rc*100)\n",
    "gold_rp= jiwer.RemovePunctuation()(gold_list)\n",
    "test_rp = jiwer.RemovePunctuation()(test_list)\n",
    "print(\"C-WER\")\n",
    "wer_rp = get_detail_wer(gold_rp, test_rp)\n",
    "# print(\"WER removing punctuation:\", wer_rp*100)\n",
    "gold_rc_rp= jiwer.RemovePunctuation()(gold_rc)\n",
    "test_rc_rp = jiwer.RemovePunctuation()(test_rc)\n",
    "wer_rc_rp = get_detail_wer(gold_rc_rp, test_rc_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative CER is  45.921846315237346\n",
      "Relative PER is  74.840098400984\n"
     ]
    }
   ],
   "source": [
    "get_c_p_er_fr_wer_ami(wer=37.465693679126865,C_WER=41.19098780928877,P_WER=42.97698293218218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
