{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# model_silero_te, example_texts, languages, punct, apply_te = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "#                                                                   model='silero_te')\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize,TreebankWordTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "# load model and processor\n",
    "import os\n",
    "# import librosa\n",
    "import jiwer\n",
    "import string\n",
    "import csv\n",
    "from autocorrect import Speller\n",
    "spell = Speller()\n",
    "from transformers import pipeline\n",
    "\n",
    "# fix_spelling = pipeline(\"text2text-generation\",model=\"oliverguhr/spelling-correction-english-base\")\n",
    "\n",
    "\n",
    "def get_gold_hyp_lists(gold_path,test_path,septype):\n",
    "    def create_hyp_sentence_dictionary(filename):\n",
    "        sentence_dict = {}\n",
    "        with open(filename, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for idx,line in enumerate(lines):\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    sentence_id, sentence = line.split(septype,1)\n",
    "                    # sentence_id=sentence_id+\".wav\" # for AMI\n",
    "                    sentence_dict[sentence_id] = sentence\n",
    "        return sentence_dict\n",
    "\n",
    "    def create_gold_sentence_dictionary(filename):\n",
    "        sentence_dict = {}\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.split(' ', 1) # Libri\n",
    "                # parts = line.split(',', 1) # AMI\n",
    "                sentence_id, sentence = parts\n",
    "                if sentence.strip()!='':\n",
    "                    sentence_dict[sentence_id] = sentence.strip()\n",
    "        return sentence_dict\n",
    "    \n",
    "    def read_csv_to_dict(file_path):\n",
    "        result_dict = {}\n",
    "        with open(file_path, 'r') as csvfile:\n",
    "            csv_reader = csv.reader(csvfile)\n",
    "            for row in csv_reader:\n",
    "                key, value = row[0], row[1]\n",
    "                key=key.split('/')[1]\n",
    "                # print(key,value)\n",
    "                # break\n",
    "                result_dict[key] = value\n",
    "        return result_dict\n",
    "    \n",
    "    gold_dict = create_gold_sentence_dictionary(gold_path)\n",
    "    # gold_dict = read_csv_to_dict(gold_path)\n",
    "    test_dict = create_hyp_sentence_dictionary(test_path)\n",
    "    \n",
    "    gold_list = []\n",
    "    test_list = []\n",
    "    for test_key, test_value in test_dict.items():\n",
    "        if test_key in gold_dict:\n",
    "            gold = gold_dict[test_key]\n",
    "            gold_list.append(gold)\n",
    "            test_list.append(test_value)\n",
    "    print(len(test_list))\n",
    "    return gold_list,test_list\n",
    "\n",
    "def add_space_before_punctuation(text):\n",
    "    # List of punctuation marks\n",
    "    punctuation_marks = string.punctuation\n",
    "\n",
    "    # Iterate over each character in the text\n",
    "    modified_text = ''\n",
    "    for char in text:\n",
    "        if char in punctuation_marks:\n",
    "            modified_text += ' ' + char\n",
    "        else:\n",
    "            modified_text += char\n",
    "\n",
    "    return modified_text\n",
    "\n",
    "def add_space_before_punctuation(text):\n",
    "    # List of punctuation marks\n",
    "    punctuation_marks = string.punctuation\n",
    "\n",
    "    # Iterate over each character in the text\n",
    "    modified_text = ''\n",
    "    for char in text:\n",
    "        if char in punctuation_marks:\n",
    "            modified_text += ' ' + char\n",
    "        else:\n",
    "            modified_text += char\n",
    "\n",
    "    return modified_text\n",
    "\n",
    "def add_space(reference_list, hypothesis_list):\n",
    "    reference = []\n",
    "    hypothesis = []\n",
    "    for ref, hyp in zip(reference_list, hypothesis_list):\n",
    "        # Preprocess sentences to keep punctuation as separate words\n",
    "        reference.append(add_space_before_punctuation(ref))\n",
    "        hypothesis.append(add_space_before_punctuation(hyp))\n",
    "        # print(reference,hypothesis)\n",
    "        # Calculate WER\n",
    "       \n",
    "    #     wer = jiwer.wer(reference, hypothesis)\n",
    "    #     # print(wer)\n",
    "    #     wer_scores.append(wer)\n",
    "    # wer_mean=sum(wer_scores) / len(wer_scores)\n",
    "    \n",
    "    return reference,hypothesis\n",
    "\n",
    "def get_detail_wer(gold_list,test_list):\n",
    "    out = jiwer.process_words(\n",
    "            gold_list,\n",
    "                test_list,\n",
    "            )\n",
    "    print(\"wer: \",out.wer*100)\n",
    "    print(\"hits: \",out.hits)\n",
    "    print(\"substitutions: \",out.substitutions)\n",
    "    print(\"insertions: \",out.insertions)\n",
    "    print(\"deletions: \",out.deletions)\n",
    "    print(\"total words: \",out.hits+out.substitutions+out.deletions)\n",
    "\n",
    "# def get_t_p_wer(substitutions, insertions,deletions,total_words_punc, P_WER):\n",
    "#     t_p_wer=(substitutions+insertions+deletions)/total_words_punc\n",
    "#     print(\"Topline of P-WER is \",t_p_wer*100)\n",
    "#     print(\"Relative PER is \", P_WER-t_p_wer*100)\n",
    "\n",
    "def get_c_p_er_fr_wer(wer,C_WER,P_WER,clean=True):\n",
    "    if clean:\n",
    "        total_words=50082\n",
    "        total_words_punt=57312\n",
    "        cased_words=3849\n",
    "        p_num = 9709\n",
    "    else:\n",
    "        total_words=48488\n",
    "        total_words_punt=55896\n",
    "        cased_words=4231\n",
    "        p_num = 9408\n",
    "    error_words = wer*total_words\n",
    "    error_c = C_WER*total_words\n",
    "    cer=(error_c-error_words)/cased_words\n",
    "    error_p = P_WER*total_words_punt\n",
    "    per=(error_p-error_words)/p_num\n",
    "    # print(\"Topline of P-WER is \",t_p_wer)\n",
    "    print(\"Relative CER is \", cer)\n",
    "    print(\"Relative PER is \", per)\n",
    "\n",
    "def get_c_p_er_fr_wer_ami(wer,C_WER,P_WER):\n",
    "    # if clean:\n",
    "    total_words=94006\n",
    "    total_words_punt=110266\n",
    "    cased_words=7626\n",
    "    p_num = 16260\n",
    "    error_words = wer*total_words\n",
    "    error_c = C_WER*total_words\n",
    "    cer=(error_c-error_words)/cased_words\n",
    "    error_p = P_WER*total_words_punt\n",
    "    per=(error_p-error_words)/p_num\n",
    "    print(\"Relative CER is \", cer)\n",
    "    print(\"Relative PER is \", per)\n",
    "\n",
    "def get_cased_word(text_list):\n",
    "    capitalized_word_count = 0\n",
    "\n",
    "    # Iterate through the list of text\n",
    "    for text in text_list:\n",
    "        # Split the text into words\n",
    "        words = text.split()\n",
    "        \n",
    "        # Check each word in the text\n",
    "        for word in words:\n",
    "            # Check if the word is capitalized (first character is uppercase)\n",
    "            if word.isalpha() and word[0].isupper():\n",
    "                capitalized_word_count += 1\n",
    "    print(\"Cased words number is \", capitalized_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2488\n",
      "CP-WER\n",
      "wer:  9.121998883305416\n",
      "hits:  52601\n",
      "substitutions:  3661\n",
      "insertions:  517\n",
      "deletions:  1050\n",
      "total words:  57312\n",
      "P-WER\n",
      "wer:  7.2986460078168625\n",
      "hits:  53647\n",
      "substitutions:  2614\n",
      "insertions:  518\n",
      "deletions:  1051\n",
      "total words:  57312\n",
      "C-WER\n",
      "wer:  4.628409408569945\n",
      "hits:  47884\n",
      "substitutions:  2044\n",
      "insertions:  120\n",
      "deletions:  154\n",
      "total words:  50082\n",
      "wer:  2.459965656323629\n",
      "hits:  48970\n",
      "substitutions:  958\n",
      "insertions:  120\n",
      "deletions:  154\n",
      "total words:  50082\n"
     ]
    }
   ],
   "source": [
    "gold_list,test_list = get_gold_hyp_lists(\"/Users/ccui/Desktop/dictation/books-transcription/test-clean-rich-book.txt\",\"clean.txt\",',')\n",
    "# get_cased_word(gold_list)\n",
    "gold_list,test_list= add_space(gold_list,test_list)\n",
    "print(\"CP-WER\")\n",
    "total_wer = get_detail_wer(gold_list, test_list)\n",
    "gold_rc= jiwer.ToLowerCase()(gold_list)\n",
    "test_rc = jiwer.ToLowerCase()(test_list)\n",
    "print(\"P-WER\")\n",
    "wer_rc = get_detail_wer(gold_rc, test_rc)\n",
    "# print(\"WER removing case:\", wer_rc*100)\n",
    "gold_rp= jiwer.RemovePunctuation()(gold_list)\n",
    "test_rp = jiwer.RemovePunctuation()(test_list)\n",
    "# gold_rp,test_rp= add_space(gold_rp,test_rp)\n",
    "print(\"C-WER\")\n",
    "wer_rp = get_detail_wer(gold_rp, test_rp)\n",
    "# print(\"WER removing punctuation:\", wer_rp*100)\n",
    "gold_rc_rp= jiwer.RemovePunctuation()(gold_rc)\n",
    "test_rc_rp = jiwer.RemovePunctuation()(test_rc)\n",
    "wer_rc_rp = get_detail_wer(gold_rc_rp, test_rc_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative CER is  28.215120810600155\n",
      "Relative PER is  30.394479349057576\n"
     ]
    }
   ],
   "source": [
    "get_c_p_er_fr_wer(wer=2.459965656323629,C_WER=4.628409408569945,P_WER=7.2986460078168625,clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2727\n",
      "CP-WER\n",
      "wer:  11.940031487047374\n",
      "hits:  49928\n",
      "substitutions:  4934\n",
      "insertions:  706\n",
      "deletions:  1034\n",
      "total words:  55896\n",
      "P-WER\n",
      "wer:  10.10984685845141\n",
      "hits:  50948\n",
      "substitutions:  3917\n",
      "insertions:  703\n",
      "deletions:  1031\n",
      "total words:  55896\n",
      "C-WER\n",
      "wer:  7.927734697244679\n",
      "hits:  44900\n",
      "substitutions:  3284\n",
      "insertions:  256\n",
      "deletions:  304\n",
      "total words:  48488\n",
      "WER\n",
      "wer:  5.73337733047352\n",
      "hits:  45964\n",
      "substitutions:  2220\n",
      "insertions:  256\n",
      "deletions:  304\n",
      "total words:  48488\n"
     ]
    }
   ],
   "source": [
    "gold_list,test_list = get_gold_hyp_lists(\"/Users/ccui/Desktop/dictation/books-transcription/test-other-rich-book.txt\",\"other.txt\",',')\n",
    "# get_cased_word(gold_list)\n",
    "gold_list,test_list= add_space(gold_list,test_list)\n",
    "print(\"CP-WER\")\n",
    "total_wer = get_detail_wer(gold_list, test_list)\n",
    "# print(\"Total WER:\", total_wer*100)\n",
    "gold_rc= jiwer.ToLowerCase()(gold_list)\n",
    "test_rc = jiwer.ToLowerCase()(test_list)\n",
    "print(\"P-WER\")\n",
    "wer_rc = get_detail_wer(gold_rc, test_rc)\n",
    "# print(\"WER removing case:\", wer_rc*100)\n",
    "gold_rp= jiwer.RemovePunctuation()(gold_list)\n",
    "test_rp = jiwer.RemovePunctuation()(test_list)\n",
    "# gold_rp,test_rp= add_space(gold_rp,test_rp)\n",
    "print(\"C-WER\")\n",
    "wer_rp = get_detail_wer(gold_rp, test_rp)\n",
    "# print(\"WER removing punctuation:\", wer_rp*100)\n",
    "gold_rc_rp= jiwer.RemovePunctuation()(gold_rc)\n",
    "test_rc_rp = jiwer.RemovePunctuation()(test_rc)\n",
    "print(\"WER\")\n",
    "wer_rc_rp = get_detail_wer(gold_rc_rp, test_rc_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative CER is  25.14771921531553\n",
      "Relative PER is  30.51658163265306\n"
     ]
    }
   ],
   "source": [
    "get_c_p_er_fr_wer(wer=5.73337733047352,C_WER=7.927734697244679,P_WER=10.10984685845141,clean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9474\n",
      "CP-WER\n",
      "wer:  50.61941124190593\n",
      "hits:  58836\n",
      "substitutions:  27429\n",
      "insertions:  4386\n",
      "deletions:  24001\n",
      "total words:  110266\n",
      "P-WER\n",
      "wer:  48.06558685360854\n",
      "hits:  61724\n",
      "substitutions:  24469\n",
      "insertions:  4458\n",
      "deletions:  24073\n",
      "total words:  110266\n",
      "C-WER\n",
      "wer:  42.72705997489522\n",
      "hits:  56010\n",
      "substitutions:  22030\n",
      "insertions:  2170\n",
      "deletions:  15966\n",
      "total words:  94006\n",
      "wer:  39.59747250175521\n",
      "hits:  58995\n",
      "substitutions:  19002\n",
      "insertions:  2213\n",
      "deletions:  16009\n",
      "total words:  94006\n"
     ]
    }
   ],
   "source": [
    "gold_list,test_list = get_gold_hyp_lists(\"/Users/ccui/Desktop/dictation/vasr/calculate_wer/ami_test_gold_process.txt\",\"ihm.txt\",',')\n",
    "# get_cased_word(gold_list)\n",
    "gold_list,test_list= add_space(gold_list,test_list)\n",
    "print(\"CP-WER\")\n",
    "total_wer = get_detail_wer(gold_list, test_list)\n",
    "# print(\"Total WER:\", total_wer*100)\n",
    "gold_rc= jiwer.ToLowerCase()(gold_list)\n",
    "test_rc = jiwer.ToLowerCase()(test_list)\n",
    "print(\"P-WER\")\n",
    "wer_rc = get_detail_wer(gold_rc, test_rc)\n",
    "# print(\"WER removing case:\", wer_rc*100)\n",
    "gold_rp= jiwer.RemovePunctuation()(gold_list)\n",
    "test_rp = jiwer.RemovePunctuation()(test_list)\n",
    "print(\"C-WER\")\n",
    "wer_rp = get_detail_wer(gold_rp, test_rp)\n",
    "# print(\"WER removing punctuation:\", wer_rp*100)\n",
    "gold_rc_rp= jiwer.RemovePunctuation()(gold_rc)\n",
    "test_rc_rp = jiwer.RemovePunctuation()(test_rc)\n",
    "wer_rc_rp = get_detail_wer(gold_rc_rp, test_rc_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative CER is  38.578547075793274\n",
      "Relative PER is  97.02337023370231\n"
     ]
    }
   ],
   "source": [
    "get_c_p_er_fr_wer_ami(wer=39.59747250175521,C_WER=42.72705997489522,P_WER=48.06558685360854)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
