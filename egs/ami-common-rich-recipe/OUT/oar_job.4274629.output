2023-08-27 11:00:45,004 INFO [train_noCtc.py:958] (3/4) Training started
2023-08-27 11:00:45,004 INFO [train_noCtc.py:968] (3/4) Device: cuda:3
2023-08-27 11:00:45,006 INFO [train_noCtc.py:958] (1/4) Training started
2023-08-27 11:00:45,007 INFO [train_noCtc.py:968] (1/4) Device: cuda:1
2023-08-27 11:00:45,009 INFO [train_noCtc.py:958] (0/4) Training started
2023-08-27 11:00:45,010 INFO [train_noCtc.py:977] (1/4) {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 50, 'reset_interval': 200, 'valid_interval': 700, 'feature_dim': 80, 'subsampling_factor': 4, 'dim_feedforward': 2048, 'decoder_dim': 512, 'joiner_dim': 512, 'model_warm_step': 700, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.16.0', 'torch-version': '2.0.1+cu117', 'torch-cuda-available': True, 'torch-cuda-version': '11.7', 'python-version': '3.9', 'icefall-git-branch': 'master', 'icefall-git-sha1': '968ebd2-clean', 'icefall-git-date': 'Tue Jun 27 08:35:59 2023', 'icefall-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/icefall', 'k2-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/miniconda3/envs/dictation_dev/lib/python3.9/site-packages/k2/__init__.py', 'lhotse-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/miniconda3/envs/dictation_dev/lib/python3.9/site-packages/lhotse/__init__.py', 'hostname': 'grue-1.nancy.grid5000.fr', 'IP address': '172.16.77.1'}, 'world_size': 4, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 30, 'start_epoch': 20, 'start_batch': 0, 'exp_dir': PosixPath('lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond'), 'bpe_model': 'data/lang_bpe_500/bpe.model', 'initial_lr': 0.003, 'lr_batches': 5000, 'lr_epochs': 10, 'context_size': 2, 'prune_range': 5, 'lm_scale': 0.25, 'am_scale': 0.0, 'simple_loss_scale': 0.5, 'ctc_loss_scale': 0.0, 'seed': 42, 'print_diagnostics': False, 'save_every_n': 4000, 'keep_last_k': 20, 'average_period': 100, 'use_fp16': True, 'num_encoder_layers': 6, 'encoder_dim': 512, 'rnn_hidden_size': 1024, 'aux_layer_period': 0, 'grad_norm_threshold': 25.0, 'manifest_dir': PosixPath('data/fbank'), 'max_duration': 750, 'bucketing_sampler': True, 'num_buckets': 30, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': True, 'drop_last': True, 'return_cuts': True, 'num_workers': 2, 'enable_spec_aug': True, 'spec_aug_time_warp_factor': 80, 'enable_musan': True, 'input_strategy': 'PrecomputedFeatures', 'blank_id': 0, 'vocab_size': 500}
2023-08-27 11:00:45,010 INFO [train_noCtc.py:977] (3/4) {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 50, 'reset_interval': 200, 'valid_interval': 700, 'feature_dim': 80, 'subsampling_factor': 4, 'dim_feedforward': 2048, 'decoder_dim': 512, 'joiner_dim': 512, 'model_warm_step': 700, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.16.0', 'torch-version': '2.0.1+cu117', 'torch-cuda-available': True, 'torch-cuda-version': '11.7', 'python-version': '3.9', 'icefall-git-branch': 'master', 'icefall-git-sha1': '968ebd2-clean', 'icefall-git-date': 'Tue Jun 27 08:35:59 2023', 'icefall-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/icefall', 'k2-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/miniconda3/envs/dictation_dev/lib/python3.9/site-packages/k2/__init__.py', 'lhotse-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/miniconda3/envs/dictation_dev/lib/python3.9/site-packages/lhotse/__init__.py', 'hostname': 'grue-1.nancy.grid5000.fr', 'IP address': '172.16.77.1'}, 'world_size': 4, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 30, 'start_epoch': 20, 'start_batch': 0, 'exp_dir': PosixPath('lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond'), 'bpe_model': 'data/lang_bpe_500/bpe.model', 'initial_lr': 0.003, 'lr_batches': 5000, 'lr_epochs': 10, 'context_size': 2, 'prune_range': 5, 'lm_scale': 0.25, 'am_scale': 0.0, 'simple_loss_scale': 0.5, 'ctc_loss_scale': 0.0, 'seed': 42, 'print_diagnostics': False, 'save_every_n': 4000, 'keep_last_k': 20, 'average_period': 100, 'use_fp16': True, 'num_encoder_layers': 6, 'encoder_dim': 512, 'rnn_hidden_size': 1024, 'aux_layer_period': 0, 'grad_norm_threshold': 25.0, 'manifest_dir': PosixPath('data/fbank'), 'max_duration': 750, 'bucketing_sampler': True, 'num_buckets': 30, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': True, 'drop_last': True, 'return_cuts': True, 'num_workers': 2, 'enable_spec_aug': True, 'spec_aug_time_warp_factor': 80, 'enable_musan': True, 'input_strategy': 'PrecomputedFeatures', 'blank_id': 0, 'vocab_size': 500}
2023-08-27 11:00:45,010 INFO [train_noCtc.py:958] (2/4) Training started
2023-08-27 11:00:45,010 INFO [train_noCtc.py:979] (1/4) About to create model
2023-08-27 11:00:45,010 INFO [train_noCtc.py:979] (3/4) About to create model
2023-08-27 11:00:45,010 INFO [train_noCtc.py:968] (2/4) Device: cuda:2
2023-08-27 11:00:45,013 INFO [train_noCtc.py:977] (2/4) {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 50, 'reset_interval': 200, 'valid_interval': 700, 'feature_dim': 80, 'subsampling_factor': 4, 'dim_feedforward': 2048, 'decoder_dim': 512, 'joiner_dim': 512, 'model_warm_step': 700, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.16.0', 'torch-version': '2.0.1+cu117', 'torch-cuda-available': True, 'torch-cuda-version': '11.7', 'python-version': '3.9', 'icefall-git-branch': 'master', 'icefall-git-sha1': '968ebd2-clean', 'icefall-git-date': 'Tue Jun 27 08:35:59 2023', 'icefall-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/icefall', 'k2-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/miniconda3/envs/dictation_dev/lib/python3.9/site-packages/k2/__init__.py', 'lhotse-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/miniconda3/envs/dictation_dev/lib/python3.9/site-packages/lhotse/__init__.py', 'hostname': 'grue-1.nancy.grid5000.fr', 'IP address': '172.16.77.1'}, 'world_size': 4, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 30, 'start_epoch': 20, 'start_batch': 0, 'exp_dir': PosixPath('lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond'), 'bpe_model': 'data/lang_bpe_500/bpe.model', 'initial_lr': 0.003, 'lr_batches': 5000, 'lr_epochs': 10, 'context_size': 2, 'prune_range': 5, 'lm_scale': 0.25, 'am_scale': 0.0, 'simple_loss_scale': 0.5, 'ctc_loss_scale': 0.0, 'seed': 42, 'print_diagnostics': False, 'save_every_n': 4000, 'keep_last_k': 20, 'average_period': 100, 'use_fp16': True, 'num_encoder_layers': 6, 'encoder_dim': 512, 'rnn_hidden_size': 1024, 'aux_layer_period': 0, 'grad_norm_threshold': 25.0, 'manifest_dir': PosixPath('data/fbank'), 'max_duration': 750, 'bucketing_sampler': True, 'num_buckets': 30, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': True, 'drop_last': True, 'return_cuts': True, 'num_workers': 2, 'enable_spec_aug': True, 'spec_aug_time_warp_factor': 80, 'enable_musan': True, 'input_strategy': 'PrecomputedFeatures', 'blank_id': 0, 'vocab_size': 500}
2023-08-27 11:00:45,013 INFO [train_noCtc.py:979] (2/4) About to create model
2023-08-27 11:00:45,013 INFO [train_noCtc.py:968] (0/4) Device: cuda:0
2023-08-27 11:00:45,015 INFO [train_noCtc.py:977] (0/4) {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 50, 'reset_interval': 200, 'valid_interval': 700, 'feature_dim': 80, 'subsampling_factor': 4, 'dim_feedforward': 2048, 'decoder_dim': 512, 'joiner_dim': 512, 'model_warm_step': 700, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.16.0', 'torch-version': '2.0.1+cu117', 'torch-cuda-available': True, 'torch-cuda-version': '11.7', 'python-version': '3.9', 'icefall-git-branch': 'master', 'icefall-git-sha1': '968ebd2-clean', 'icefall-git-date': 'Tue Jun 27 08:35:59 2023', 'icefall-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/icefall', 'k2-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/miniconda3/envs/dictation_dev/lib/python3.9/site-packages/k2/__init__.py', 'lhotse-path': '/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/ccui/miniconda3/envs/dictation_dev/lib/python3.9/site-packages/lhotse/__init__.py', 'hostname': 'grue-1.nancy.grid5000.fr', 'IP address': '172.16.77.1'}, 'world_size': 4, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 30, 'start_epoch': 20, 'start_batch': 0, 'exp_dir': PosixPath('lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond'), 'bpe_model': 'data/lang_bpe_500/bpe.model', 'initial_lr': 0.003, 'lr_batches': 5000, 'lr_epochs': 10, 'context_size': 2, 'prune_range': 5, 'lm_scale': 0.25, 'am_scale': 0.0, 'simple_loss_scale': 0.5, 'ctc_loss_scale': 0.0, 'seed': 42, 'print_diagnostics': False, 'save_every_n': 4000, 'keep_last_k': 20, 'average_period': 100, 'use_fp16': True, 'num_encoder_layers': 6, 'encoder_dim': 512, 'rnn_hidden_size': 1024, 'aux_layer_period': 0, 'grad_norm_threshold': 25.0, 'manifest_dir': PosixPath('data/fbank'), 'max_duration': 750, 'bucketing_sampler': True, 'num_buckets': 30, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': True, 'drop_last': True, 'return_cuts': True, 'num_workers': 2, 'enable_spec_aug': True, 'spec_aug_time_warp_factor': 80, 'enable_musan': True, 'input_strategy': 'PrecomputedFeatures', 'blank_id': 0, 'vocab_size': 500}
2023-08-27 11:00:45,016 INFO [train_noCtc.py:979] (0/4) About to create model
2023-08-27 11:00:45,270 INFO [train_noCtc.py:983] (2/4) Number of model parameters: 43987486
2023-08-27 11:00:45,271 INFO [checkpoint.py:112] (2/4) Loading checkpoint from lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-19.pt
2023-08-27 11:00:45,271 INFO [train_noCtc.py:983] (3/4) Number of model parameters: 43987486
2023-08-27 11:00:45,272 INFO [checkpoint.py:112] (3/4) Loading checkpoint from lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-19.pt
2023-08-27 11:00:45,286 INFO [train_noCtc.py:983] (1/4) Number of model parameters: 43987486
2023-08-27 11:00:45,287 INFO [checkpoint.py:112] (1/4) Loading checkpoint from lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-19.pt
2023-08-27 11:00:45,297 INFO [train_noCtc.py:983] (0/4) Number of model parameters: 43987486
2023-08-27 11:00:45,364 INFO [checkpoint.py:112] (0/4) Loading checkpoint from lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-19.pt
2023-08-27 11:00:49,314 INFO [checkpoint.py:131] (0/4) Loading averaged model
2023-08-27 11:00:52,541 INFO [train_noCtc.py:998] (3/4) Using DDP
2023-08-27 11:00:52,541 INFO [train_noCtc.py:998] (2/4) Using DDP
2023-08-27 11:00:52,566 INFO [train_noCtc.py:998] (0/4) Using DDP
2023-08-27 11:00:52,567 INFO [train_noCtc.py:998] (1/4) Using DDP
2023-08-27 11:00:52,907 INFO [train_noCtc.py:1006] (0/4) Loading optimizer state dict
2023-08-27 11:00:52,908 INFO [train_noCtc.py:1006] (1/4) Loading optimizer state dict
2023-08-27 11:00:52,908 INFO [train_noCtc.py:1006] (2/4) Loading optimizer state dict
2023-08-27 11:00:52,908 INFO [train_noCtc.py:1006] (3/4) Loading optimizer state dict
2023-08-27 11:00:53,237 INFO [train_noCtc.py:1014] (3/4) Loading scheduler state dict
2023-08-27 11:00:53,237 INFO [ami.py:23] (3/4) About to get AMI train cuts
2023-08-27 11:00:53,242 INFO [asr_datamodule.py:215] (3/4) Enable MUSAN
2023-08-27 11:00:53,242 INFO [asr_datamodule.py:216] (3/4) About to get Musan cuts
2023-08-27 11:00:53,254 INFO [train_noCtc.py:1014] (0/4) Loading scheduler state dict
2023-08-27 11:00:53,254 INFO [ami.py:23] (0/4) About to get AMI train cuts
2023-08-27 11:00:53,256 INFO [asr_datamodule.py:215] (0/4) Enable MUSAN
2023-08-27 11:00:53,256 INFO [asr_datamodule.py:216] (0/4) About to get Musan cuts
2023-08-27 11:00:53,261 INFO [train_noCtc.py:1014] (1/4) Loading scheduler state dict
2023-08-27 11:00:53,261 INFO [ami.py:23] (1/4) About to get AMI train cuts
2023-08-27 11:00:53,263 INFO [asr_datamodule.py:215] (1/4) Enable MUSAN
2023-08-27 11:00:53,263 INFO [asr_datamodule.py:216] (1/4) About to get Musan cuts
2023-08-27 11:00:53,269 INFO [train_noCtc.py:1014] (2/4) Loading scheduler state dict
2023-08-27 11:00:53,269 INFO [ami.py:23] (2/4) About to get AMI train cuts
2023-08-27 11:00:53,272 INFO [asr_datamodule.py:215] (2/4) Enable MUSAN
2023-08-27 11:00:53,272 INFO [asr_datamodule.py:216] (2/4) About to get Musan cuts
2023-08-27 11:00:55,383 INFO [asr_datamodule.py:244] (3/4) Enable SpecAugment
2023-08-27 11:00:55,384 INFO [asr_datamodule.py:245] (3/4) Time warp factor: 80
2023-08-27 11:00:55,384 INFO [asr_datamodule.py:257] (3/4) Num frame mask: 10
2023-08-27 11:00:55,384 INFO [asr_datamodule.py:270] (3/4) About to create train dataset
2023-08-27 11:00:55,384 INFO [asr_datamodule.py:299] (3/4) Using DynamicBucketingSampler.
2023-08-27 11:00:55,460 INFO [asr_datamodule.py:244] (2/4) Enable SpecAugment
2023-08-27 11:00:55,460 INFO [asr_datamodule.py:245] (2/4) Time warp factor: 80
2023-08-27 11:00:55,460 INFO [asr_datamodule.py:257] (2/4) Num frame mask: 10
2023-08-27 11:00:55,460 INFO [asr_datamodule.py:270] (2/4) About to create train dataset
2023-08-27 11:00:55,461 INFO [asr_datamodule.py:299] (2/4) Using DynamicBucketingSampler.
2023-08-27 11:00:55,468 INFO [asr_datamodule.py:244] (0/4) Enable SpecAugment
2023-08-27 11:00:55,468 INFO [asr_datamodule.py:245] (0/4) Time warp factor: 80
2023-08-27 11:00:55,468 INFO [asr_datamodule.py:257] (0/4) Num frame mask: 10
2023-08-27 11:00:55,468 INFO [asr_datamodule.py:270] (0/4) About to create train dataset
2023-08-27 11:00:55,468 INFO [asr_datamodule.py:299] (0/4) Using DynamicBucketingSampler.
2023-08-27 11:00:55,788 INFO [asr_datamodule.py:244] (1/4) Enable SpecAugment
2023-08-27 11:00:55,788 INFO [asr_datamodule.py:245] (1/4) Time warp factor: 80
2023-08-27 11:00:55,788 INFO [asr_datamodule.py:257] (1/4) Num frame mask: 10
2023-08-27 11:00:55,788 INFO [asr_datamodule.py:270] (1/4) About to create train dataset
2023-08-27 11:00:55,788 INFO [asr_datamodule.py:299] (1/4) Using DynamicBucketingSampler.
2023-08-27 11:01:02,929 INFO [asr_datamodule.py:314] (0/4) About to create train dataloader
2023-08-27 11:01:02,930 INFO [ami.py:30] (0/4) About to get AMI dev cuts
2023-08-27 11:01:02,998 INFO [asr_datamodule.py:345] (0/4) About to create dev dataset
2023-08-27 11:01:03,028 INFO [asr_datamodule.py:314] (3/4) About to create train dataloader
2023-08-27 11:01:03,029 INFO [ami.py:30] (3/4) About to get AMI dev cuts
2023-08-27 11:01:03,031 INFO [asr_datamodule.py:345] (3/4) About to create dev dataset
2023-08-27 11:01:03,053 INFO [asr_datamodule.py:314] (2/4) About to create train dataloader
2023-08-27 11:01:03,054 INFO [ami.py:30] (2/4) About to get AMI dev cuts
2023-08-27 11:01:03,056 INFO [asr_datamodule.py:345] (2/4) About to create dev dataset
2023-08-27 11:01:03,744 INFO [asr_datamodule.py:364] (0/4) About to create dev dataloader
2023-08-27 11:01:03,745 INFO [train_noCtc.py:1056] (0/4) Loading grad scaler state dict
2023-08-27 11:01:03,797 INFO [asr_datamodule.py:364] (3/4) About to create dev dataloader
2023-08-27 11:01:03,798 INFO [train_noCtc.py:1056] (3/4) Loading grad scaler state dict
2023-08-27 11:01:03,810 INFO [asr_datamodule.py:364] (2/4) About to create dev dataloader
2023-08-27 11:01:03,810 INFO [train_noCtc.py:1056] (2/4) Loading grad scaler state dict
2023-08-27 11:01:04,403 INFO [asr_datamodule.py:314] (1/4) About to create train dataloader
2023-08-27 11:01:04,404 INFO [ami.py:30] (1/4) About to get AMI dev cuts
2023-08-27 11:01:04,406 INFO [asr_datamodule.py:345] (1/4) About to create dev dataset
2023-08-27 11:01:05,215 INFO [asr_datamodule.py:364] (1/4) About to create dev dataloader
2023-08-27 11:01:05,216 INFO [train_noCtc.py:1056] (1/4) Loading grad scaler state dict
2023-08-27 11:01:26,712 INFO [train_noCtc.py:878] (3/4) Epoch 20, batch 0, loss[loss=0.6871, simple_loss_common=0.4578, pruned_loss_common=0.1637, simple_loss_rich=0.3116, pruned_loss_rich=0.1386, over 18042.00 frames. utt_duration=1095 frames, utt_pad_proportion=0.02412, over 66.00 utterances.], tot_loss[loss=0.6871, simple_loss_common=0.4578, pruned_loss_common=0.1637, simple_loss_rich=0.3116, pruned_loss_rich=0.1386, over 18042.00 frames. utt_duration=1095 frames, utt_pad_proportion=0.02412, over 66.00 utterances.], batch size: 66, lr: 1.85e-03
2023-08-27 11:01:26,713 INFO [train_noCtc.py:878] (1/4) Epoch 20, batch 0, loss[loss=0.9891, simple_loss_common=0.5119, pruned_loss_common=0.2901, simple_loss_rich=0.3827, pruned_loss_rich=0.2518, over 16178.00 frames. utt_duration=192.4 frames, utt_pad_proportion=0.1296, over 339.00 utterances.], tot_loss[loss=0.9891, simple_loss_common=0.5119, pruned_loss_common=0.2901, simple_loss_rich=0.3827, pruned_loss_rich=0.2518, over 16178.00 frames. utt_duration=192.4 frames, utt_pad_proportion=0.1296, over 339.00 utterances.], batch size: 339, lr: 1.85e-03
2023-08-27 11:01:26,714 INFO [train_noCtc.py:878] (2/4) Epoch 20, batch 0, loss[loss=0.6895, simple_loss_common=0.4729, pruned_loss_common=0.1551, simple_loss_rich=0.3201, pruned_loss_rich=0.1379, over 18164.00 frames. utt_duration=1011 frames, utt_pad_proportion=0.01673, over 72.00 utterances.], tot_loss[loss=0.6895, simple_loss_common=0.4729, pruned_loss_common=0.1551, simple_loss_rich=0.3201, pruned_loss_rich=0.1379, over 18164.00 frames. utt_duration=1011 frames, utt_pad_proportion=0.01673, over 72.00 utterances.], batch size: 72, lr: 1.85e-03
2023-08-27 11:01:26,716 INFO [train_noCtc.py:878] (0/4) Epoch 20, batch 0, loss[loss=0.7991, simple_loss_common=0.5341, pruned_loss_common=0.1983, simple_loss_rich=0.3497, pruned_loss_rich=0.1588, over 18281.00 frames. utt_duration=851.9 frames, utt_pad_proportion=0.01404, over 86.00 utterances.], tot_loss[loss=0.7991, simple_loss_common=0.5341, pruned_loss_common=0.1983, simple_loss_rich=0.3497, pruned_loss_rich=0.1588, over 18281.00 frames. utt_duration=851.9 frames, utt_pad_proportion=0.01404, over 86.00 utterances.], batch size: 86, lr: 1.85e-03
2023-08-27 11:01:26,941 INFO [distributed.py:1140] (0/4) Reducer buckets have been rebuilt in this iteration.
2023-08-27 11:01:26,941 INFO [distributed.py:1140] (3/4) Reducer buckets have been rebuilt in this iteration.
2023-08-27 11:01:26,941 INFO [distributed.py:1140] (2/4) Reducer buckets have been rebuilt in this iteration.
2023-08-27 11:01:26,941 INFO [distributed.py:1140] (1/4) Reducer buckets have been rebuilt in this iteration.
2023-08-27 11:02:35,895 INFO [train_noCtc.py:878] (3/4) Epoch 20, batch 50, loss[loss=0.8868, simple_loss_common=0.5721, pruned_loss_common=0.2282, simple_loss_rich=0.3775, pruned_loss_rich=0.1838, over 18247.00 frames. utt_duration=614.7 frames, utt_pad_proportion=0.02273, over 119.00 utterances.], tot_loss[loss=0.8057, simple_loss_common=0.5212, pruned_loss_common=0.2034, simple_loss_rich=0.3485, pruned_loss_rich=0.1674, over 815879.76 frames. utt_duration=605.1 frames, utt_pad_proportion=0.03486, over 5406.10 utterances.], batch size: 119, lr: 1.84e-03
2023-08-27 11:02:35,896 INFO [train_noCtc.py:878] (2/4) Epoch 20, batch 50, loss[loss=0.7883, simple_loss_common=0.5292, pruned_loss_common=0.2024, simple_loss_rich=0.3368, pruned_loss_rich=0.1529, over 18186.00 frames. utt_duration=1012 frames, utt_pad_proportion=0.0159, over 72.00 utterances.], tot_loss[loss=0.8149, simple_loss_common=0.5197, pruned_loss_common=0.2066, simple_loss_rich=0.3521, pruned_loss_rich=0.1724, over 801553.14 frames. utt_duration=476.6 frames, utt_pad_proportion=0.08312, over 6748.03 utterances.], batch size: 72, lr: 1.84e-03
2023-08-27 11:02:35,896 INFO [train_noCtc.py:878] (1/4) Epoch 20, batch 50, loss[loss=0.9088, simple_loss_common=0.5944, pruned_loss_common=0.2361, simple_loss_rich=0.3824, pruned_loss_rich=0.1843, over 18256.00 frames. utt_duration=671.2 frames, utt_pad_proportion=0.01726, over 109.00 utterances.], tot_loss[loss=0.8333, simple_loss_common=0.5207, pruned_loss_common=0.2153, simple_loss_rich=0.3553, pruned_loss_rich=0.18, over 797118.62 frames. utt_duration=425.6 frames, utt_pad_proportion=0.08031, over 7518.66 utterances.], batch size: 109, lr: 1.84e-03
2023-08-27 11:02:35,897 INFO [train_noCtc.py:878] (0/4) Epoch 20, batch 50, loss[loss=0.7552, simple_loss_common=0.5152, pruned_loss_common=0.1881, simple_loss_rich=0.3249, pruned_loss_rich=0.147, over 18349.00 frames. utt_duration=1050 frames, utt_pad_proportion=0.01962, over 70.00 utterances.], tot_loss[loss=0.8203, simple_loss_common=0.5289, pruned_loss_common=0.2078, simple_loss_rich=0.3537, pruned_loss_rich=0.1713, over 811319.33 frames. utt_duration=548.4 frames, utt_pad_proportion=0.05207, over 5933.39 utterances.], batch size: 70, lr: 1.84e-03
2023-08-27 11:03:49,405 INFO [train_noCtc.py:878] (3/4) Epoch 20, batch 100, loss[loss=0.6806, simple_loss_common=0.4811, pruned_loss_common=0.1553, simple_loss_rich=0.3115, pruned_loss_rich=0.129, over 18397.00 frames. utt_duration=909.9 frames, utt_pad_proportion=0.01416, over 81.00 utterances.], tot_loss[loss=0.8098, simple_loss_common=0.5208, pruned_loss_common=0.205, simple_loss_rich=0.3493, pruned_loss_rich=0.1697, over 1422728.91 frames. utt_duration=527 frames, utt_pad_proportion=0.06323, over 10829.10 utterances.], batch size: 81, lr: 1.84e-03
2023-08-27 11:03:49,406 INFO [train_noCtc.py:878] (2/4) Epoch 20, batch 100, loss[loss=0.6471, simple_loss_common=0.4769, pruned_loss_common=0.1381, simple_loss_rich=0.3077, pruned_loss_rich=0.1167, over 18221.00 frames. utt_duration=973.3 frames, utt_pad_proportion=0.01983, over 75.00 utterances.], tot_loss[loss=0.8131, simple_loss_common=0.5191, pruned_loss_common=0.2072, simple_loss_rich=0.3499, pruned_loss_rich=0.1714, over 1416982.97 frames. utt_duration=503.1 frames, utt_pad_proportion=0.07042, over 11298.61 utterances.], batch size: 75, lr: 1.84e-03
2023-08-27 11:03:49,407 INFO [train_noCtc.py:878] (1/4) Epoch 20, batch 100, loss[loss=0.8235, simple_loss_common=0.5542, pruned_loss_common=0.202, simple_loss_rich=0.361, pruned_loss_rich=0.164, over 18164.00 frames. utt_duration=587.5 frames, utt_pad_proportion=0.02411, over 124.00 utterances.], tot_loss[loss=0.8319, simple_loss_common=0.5228, pruned_loss_common=0.2149, simple_loss_rich=0.3546, pruned_loss_rich=0.1783, over 1412418.89 frames. utt_duration=452.3 frames, utt_pad_proportion=0.06538, over 12530.70 utterances.], batch size: 124, lr: 1.84e-03
2023-08-27 11:03:49,407 INFO [train_noCtc.py:878] (0/4) Epoch 20, batch 100, loss[loss=0.8575, simple_loss_common=0.4536, pruned_loss_common=0.2249, simple_loss_rich=0.3706, pruned_loss_rich=0.2205, over 14744.00 frames. utt_duration=130.6 frames, utt_pad_proportion=0.2039, over 457.00 utterances.], tot_loss[loss=0.8224, simple_loss_common=0.5284, pruned_loss_common=0.2085, simple_loss_rich=0.3548, pruned_loss_rich=0.1723, over 1422490.02 frames. utt_duration=507.5 frames, utt_pad_proportion=0.06355, over 11245.23 utterances.], batch size: 457, lr: 1.84e-03
2023-08-27 11:05:01,212 INFO [train_noCtc.py:878] (3/4) Epoch 20, batch 150, loss[loss=0.9025, simple_loss_common=0.5204, pruned_loss_common=0.2509, simple_loss_rich=0.3677, pruned_loss_rich=0.2076, over 17325.00 frames. utt_duration=288.9 frames, utt_pad_proportion=0.068, over 241.00 utterances.], tot_loss[loss=0.8143, simple_loss_common=0.5233, pruned_loss_common=0.207, simple_loss_rich=0.3502, pruned_loss_rich=0.1705, over 1904577.44 frames. utt_duration=538 frames, utt_pad_proportion=0.05734, over 14199.91 utterances.], batch size: 241, lr: 1.84e-03
2023-08-27 11:05:01,213 INFO [train_noCtc.py:878] (2/4) Epoch 20, batch 150, loss[loss=0.7211, simple_loss_common=0.5012, pruned_loss_common=0.1714, simple_loss_rich=0.3251, pruned_loss_rich=0.1366, over 18391.00 frames. utt_duration=909.7 frames, utt_pad_proportion=0.01553, over 81.00 utterances.], tot_loss[loss=0.8148, simple_loss_common=0.5206, pruned_loss_common=0.2078, simple_loss_rich=0.3501, pruned_loss_rich=0.1716, over 1896166.54 frames. utt_duration=511 frames, utt_pad_proportion=0.06781, over 14886.14 utterances.], batch size: 81, lr: 1.84e-03
2023-08-27 11:05:01,213 INFO [train_noCtc.py:878] (0/4) Epoch 20, batch 150, loss[loss=0.7355, simple_loss_common=0.4771, pruned_loss_common=0.1856, simple_loss_rich=0.3191, pruned_loss_rich=0.1518, over 18068.00 frames. utt_duration=1096 frames, utt_pad_proportion=0.02376, over 66.00 utterances.], tot_loss[loss=0.8155, simple_loss_common=0.5268, pruned_loss_common=0.206, simple_loss_rich=0.3526, pruned_loss_rich=0.1698, over 1906642.95 frames. utt_duration=539.7 frames, utt_pad_proportion=0.05688, over 14169.09 utterances.], batch size: 66, lr: 1.84e-03
2023-08-27 11:05:01,214 INFO [train_noCtc.py:878] (1/4) Epoch 20, batch 150, loss[loss=0.9149, simple_loss_common=0.5491, pruned_loss_common=0.2471, simple_loss_rich=0.3804, pruned_loss_rich=0.203, over 17667.00 frames. utt_duration=414.7 frames, utt_pad_proportion=0.04892, over 171.00 utterances.], tot_loss[loss=0.8289, simple_loss_common=0.5223, pruned_loss_common=0.2137, simple_loss_rich=0.3538, pruned_loss_rich=0.1772, over 1880732.66 frames. utt_duration=442.2 frames, utt_pad_proportion=0.07756, over 17070.57 utterances.], batch size: 171, lr: 1.84e-03
2023-08-27 11:05:45,014 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-20.pt
2023-08-27 11:06:05,022 INFO [train_noCtc.py:878] (3/4) Epoch 21, batch 0, loss[loss=0.7089, simple_loss_common=0.4755, pruned_loss_common=0.1679, simple_loss_rich=0.3204, pruned_loss_rich=0.1431, over 18241.00 frames. utt_duration=974.4 frames, utt_pad_proportion=0.01778, over 75.00 utterances.], tot_loss[loss=0.7089, simple_loss_common=0.4755, pruned_loss_common=0.1679, simple_loss_rich=0.3204, pruned_loss_rich=0.1431, over 18241.00 frames. utt_duration=974.4 frames, utt_pad_proportion=0.01778, over 75.00 utterances.], batch size: 75, lr: 1.80e-03
2023-08-27 11:06:05,023 INFO [train_noCtc.py:878] (1/4) Epoch 21, batch 0, loss[loss=0.7483, simple_loss_common=0.5097, pruned_loss_common=0.1791, simple_loss_rich=0.3374, pruned_loss_rich=0.1456, over 18380.00 frames. utt_duration=909.1 frames, utt_pad_proportion=0.01509, over 81.00 utterances.], tot_loss[loss=0.7483, simple_loss_common=0.5097, pruned_loss_common=0.1791, simple_loss_rich=0.3374, pruned_loss_rich=0.1456, over 18380.00 frames. utt_duration=909.1 frames, utt_pad_proportion=0.01509, over 81.00 utterances.], batch size: 81, lr: 1.80e-03
2023-08-27 11:06:05,024 INFO [train_noCtc.py:878] (0/4) Epoch 21, batch 0, loss[loss=0.6855, simple_loss_common=0.4602, pruned_loss_common=0.168, simple_loss_rich=0.302, pruned_loss_rich=0.1364, over 18005.00 frames. utt_duration=1092 frames, utt_pad_proportion=0.02633, over 66.00 utterances.], tot_loss[loss=0.6855, simple_loss_common=0.4602, pruned_loss_common=0.168, simple_loss_rich=0.302, pruned_loss_rich=0.1364, over 18005.00 frames. utt_duration=1092 frames, utt_pad_proportion=0.02633, over 66.00 utterances.], batch size: 66, lr: 1.80e-03
2023-08-27 11:06:05,024 INFO [train_noCtc.py:878] (2/4) Epoch 21, batch 0, loss[loss=0.8062, simple_loss_common=0.5374, pruned_loss_common=0.2023, simple_loss_rich=0.3521, pruned_loss_rich=0.1591, over 18265.00 frames. utt_duration=851.4 frames, utt_pad_proportion=0.01462, over 86.00 utterances.], tot_loss[loss=0.8062, simple_loss_common=0.5374, pruned_loss_common=0.2023, simple_loss_rich=0.3521, pruned_loss_rich=0.1591, over 18265.00 frames. utt_duration=851.4 frames, utt_pad_proportion=0.01462, over 86.00 utterances.], batch size: 86, lr: 1.80e-03
2023-08-27 11:07:14,629 INFO [train_noCtc.py:878] (3/4) Epoch 21, batch 50, loss[loss=0.7527, simple_loss_common=0.5104, pruned_loss_common=0.1783, simple_loss_rich=0.3403, pruned_loss_rich=0.149, over 18314.00 frames. utt_duration=797.7 frames, utt_pad_proportion=0.01635, over 92.00 utterances.], tot_loss[loss=0.8309, simple_loss_common=0.5237, pruned_loss_common=0.2128, simple_loss_rich=0.3564, pruned_loss_rich=0.1781, over 798493.65 frames. utt_duration=434.1 frames, utt_pad_proportion=0.08108, over 7383.14 utterances.], batch size: 92, lr: 1.79e-03
2023-08-27 11:07:14,630 INFO [train_noCtc.py:878] (1/4) Epoch 21, batch 50, loss[loss=0.8346, simple_loss_common=0.5232, pruned_loss_common=0.2173, simple_loss_rich=0.3568, pruned_loss_rich=0.1773, over 17686.00 frames. utt_duration=373.8 frames, utt_pad_proportion=0.05118, over 190.00 utterances.], tot_loss[loss=0.8199, simple_loss_common=0.5194, pruned_loss_common=0.2105, simple_loss_rich=0.3513, pruned_loss_rich=0.174, over 803322.30 frames. utt_duration=480.9 frames, utt_pad_proportion=0.07321, over 6702.49 utterances.], batch size: 190, lr: 1.79e-03
2023-08-27 11:07:14,630 INFO [train_noCtc.py:878] (2/4) Epoch 21, batch 50, loss[loss=0.7052, simple_loss_common=0.487, pruned_loss_common=0.1614, simple_loss_rich=0.3236, pruned_loss_rich=0.1386, over 18208.00 frames. utt_duration=878.8 frames, utt_pad_proportion=0.01813, over 83.00 utterances.], tot_loss[loss=0.826, simple_loss_common=0.5233, pruned_loss_common=0.2124, simple_loss_rich=0.353, pruned_loss_rich=0.1754, over 801265.15 frames. utt_duration=458.6 frames, utt_pad_proportion=0.07221, over 7011.43 utterances.], batch size: 83, lr: 1.79e-03
2023-08-27 11:07:14,632 INFO [train_noCtc.py:878] (0/4) Epoch 21, batch 50, loss[loss=0.8012, simple_loss_common=0.5171, pruned_loss_common=0.1961, simple_loss_rich=0.3579, pruned_loss_rich=0.1676, over 17884.00 frames. utt_duration=457.1 frames, utt_pad_proportion=0.03768, over 157.00 utterances.], tot_loss[loss=0.809, simple_loss_common=0.5224, pruned_loss_common=0.2045, simple_loss_rich=0.3499, pruned_loss_rich=0.1684, over 811249.83 frames. utt_duration=553.5 frames, utt_pad_proportion=0.04924, over 5877.62 utterances.], batch size: 157, lr: 1.79e-03
2023-08-27 11:08:27,664 INFO [train_noCtc.py:878] (1/4) Epoch 21, batch 100, loss[loss=0.7839, simple_loss_common=0.5084, pruned_loss_common=0.1912, simple_loss_rich=0.3468, pruned_loss_rich=0.1651, over 18034.00 frames. utt_duration=492.2 frames, utt_pad_proportion=0.03305, over 147.00 utterances.], tot_loss[loss=0.8026, simple_loss_common=0.5155, pruned_loss_common=0.2029, simple_loss_rich=0.3475, pruned_loss_rich=0.1682, over 1417723.08 frames. utt_duration=492.7 frames, utt_pad_proportion=0.06776, over 11544.88 utterances.], batch size: 147, lr: 1.79e-03
2023-08-27 11:08:27,664 INFO [train_noCtc.py:878] (3/4) Epoch 21, batch 100, loss[loss=0.7711, simple_loss_common=0.5163, pruned_loss_common=0.1906, simple_loss_rich=0.3416, pruned_loss_rich=0.1516, over 18289.00 frames. utt_duration=643.1 frames, utt_pad_proportion=0.02115, over 114.00 utterances.], tot_loss[loss=0.8086, simple_loss_common=0.518, pruned_loss_common=0.205, simple_loss_rich=0.3495, pruned_loss_rich=0.17, over 1415914.81 frames. utt_duration=489 frames, utt_pad_proportion=0.07032, over 11617.61 utterances.], batch size: 114, lr: 1.79e-03
2023-08-27 11:08:27,665 INFO [train_noCtc.py:878] (2/4) Epoch 21, batch 100, loss[loss=0.7808, simple_loss_common=0.5298, pruned_loss_common=0.1958, simple_loss_rich=0.3396, pruned_loss_rich=0.1503, over 18230.00 frames. utt_duration=849.7 frames, utt_pad_proportion=0.01651, over 86.00 utterances.], tot_loss[loss=0.8093, simple_loss_common=0.52, pruned_loss_common=0.2061, simple_loss_rich=0.3489, pruned_loss_rich=0.1687, over 1422868.72 frames. utt_duration=518.6 frames, utt_pad_proportion=0.05725, over 11007.08 utterances.], batch size: 86, lr: 1.79e-03
2023-08-27 11:08:27,669 INFO [train_noCtc.py:878] (0/4) Epoch 21, batch 100, loss[loss=0.7686, simple_loss_common=0.5218, pruned_loss_common=0.1835, simple_loss_rich=0.3447, pruned_loss_rich=0.1519, over 18344.00 frames. utt_duration=693.9 frames, utt_pad_proportion=0.01857, over 106.00 utterances.], tot_loss[loss=0.8035, simple_loss_common=0.5203, pruned_loss_common=0.2023, simple_loss_rich=0.3492, pruned_loss_rich=0.1665, over 1425320.09 frames. utt_duration=531.9 frames, utt_pad_proportion=0.05735, over 10747.79 utterances.], batch size: 106, lr: 1.79e-03
2023-08-27 11:09:35,871 INFO [train_noCtc.py:878] (1/4) Epoch 21, batch 150, loss[loss=0.984, simple_loss_common=0.5324, pruned_loss_common=0.2908, simple_loss_rich=0.3771, pruned_loss_rich=0.2385, over 16890.00 frames. utt_duration=244.5 frames, utt_pad_proportion=0.09098, over 278.00 utterances.], tot_loss[loss=0.8036, simple_loss_common=0.5159, pruned_loss_common=0.2032, simple_loss_rich=0.3481, pruned_loss_rich=0.1685, over 1892119.45 frames. utt_duration=486.9 frames, utt_pad_proportion=0.07195, over 15591.69 utterances.], batch size: 278, lr: 1.78e-03
2023-08-27 11:09:35,871 INFO [train_noCtc.py:878] (2/4) Epoch 21, batch 150, loss[loss=0.9334, simple_loss_common=0.5296, pruned_loss_common=0.2661, simple_loss_rich=0.3671, pruned_loss_rich=0.219, over 17386.00 frames. utt_duration=290.1 frames, utt_pad_proportion=0.06734, over 241.00 utterances.], tot_loss[loss=0.8106, simple_loss_common=0.5216, pruned_loss_common=0.2055, simple_loss_rich=0.35, pruned_loss_rich=0.1693, over 1899524.34 frames. utt_duration=510.5 frames, utt_pad_proportion=0.06288, over 14927.89 utterances.], batch size: 241, lr: 1.78e-03
2023-08-27 11:09:35,872 INFO [train_noCtc.py:878] (0/4) Epoch 21, batch 150, loss[loss=0.8966, simple_loss_common=0.4874, pruned_loss_common=0.2311, simple_loss_rich=0.3801, pruned_loss_rich=0.2318, over 14833.00 frames. utt_duration=131.3 frames, utt_pad_proportion=0.1993, over 457.00 utterances.], tot_loss[loss=0.8128, simple_loss_common=0.5198, pruned_loss_common=0.2066, simple_loss_rich=0.351, pruned_loss_rich=0.1708, over 1893296.67 frames. utt_duration=482.9 frames, utt_pad_proportion=0.06797, over 15729.80 utterances.], batch size: 457, lr: 1.78e-03
2023-08-27 11:09:35,872 INFO [train_noCtc.py:878] (3/4) Epoch 21, batch 150, loss[loss=1.103, simple_loss_common=0.5557, pruned_loss_common=0.3479, simple_loss_rich=0.404, pruned_loss_rich=0.275, over 16170.00 frames. utt_duration=191.7 frames, utt_pad_proportion=0.1285, over 340.00 utterances.], tot_loss[loss=0.8172, simple_loss_common=0.5189, pruned_loss_common=0.2088, simple_loss_rich=0.3513, pruned_loss_rich=0.1733, over 1885138.30 frames. utt_duration=463.6 frames, utt_pad_proportion=0.07775, over 16318.59 utterances.], batch size: 340, lr: 1.78e-03
2023-08-27 11:10:19,092 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-21.pt
2023-08-27 11:10:39,512 INFO [train_noCtc.py:878] (3/4) Epoch 22, batch 0, loss[loss=0.8162, simple_loss_common=0.5578, pruned_loss_common=0.1941, simple_loss_rich=0.3656, pruned_loss_rich=0.1604, over 18306.00 frames. utt_duration=643.8 frames, utt_pad_proportion=0.02009, over 114.00 utterances.], tot_loss[loss=0.8162, simple_loss_common=0.5578, pruned_loss_common=0.1941, simple_loss_rich=0.3656, pruned_loss_rich=0.1604, over 18306.00 frames. utt_duration=643.8 frames, utt_pad_proportion=0.02009, over 114.00 utterances.], batch size: 114, lr: 1.74e-03
2023-08-27 11:10:39,513 INFO [train_noCtc.py:878] (1/4) Epoch 22, batch 0, loss[loss=0.8157, simple_loss_common=0.5373, pruned_loss_common=0.2045, simple_loss_rich=0.3532, pruned_loss_rich=0.1659, over 18277.00 frames. utt_duration=642.7 frames, utt_pad_proportion=0.02172, over 114.00 utterances.], tot_loss[loss=0.8157, simple_loss_common=0.5373, pruned_loss_common=0.2045, simple_loss_rich=0.3532, pruned_loss_rich=0.1659, over 18277.00 frames. utt_duration=642.7 frames, utt_pad_proportion=0.02172, over 114.00 utterances.], batch size: 114, lr: 1.74e-03
2023-08-27 11:10:39,513 INFO [train_noCtc.py:878] (2/4) Epoch 22, batch 0, loss[loss=0.7075, simple_loss_common=0.5111, pruned_loss_common=0.1544, simple_loss_rich=0.3297, pruned_loss_rich=0.1327, over 18196.00 frames. utt_duration=878.5 frames, utt_pad_proportion=0.01846, over 83.00 utterances.], tot_loss[loss=0.7075, simple_loss_common=0.5111, pruned_loss_common=0.1544, simple_loss_rich=0.3297, pruned_loss_rich=0.1327, over 18196.00 frames. utt_duration=878.5 frames, utt_pad_proportion=0.01846, over 83.00 utterances.], batch size: 83, lr: 1.74e-03
2023-08-27 11:10:39,519 INFO [train_noCtc.py:878] (0/4) Epoch 22, batch 0, loss[loss=0.8433, simple_loss_common=0.5256, pruned_loss_common=0.2178, simple_loss_rich=0.3566, pruned_loss_rich=0.1844, over 17719.00 frames. utt_duration=374.6 frames, utt_pad_proportion=0.04933, over 190.00 utterances.], tot_loss[loss=0.8433, simple_loss_common=0.5256, pruned_loss_common=0.2178, simple_loss_rich=0.3566, pruned_loss_rich=0.1844, over 17719.00 frames. utt_duration=374.6 frames, utt_pad_proportion=0.04933, over 190.00 utterances.], batch size: 190, lr: 1.74e-03
2023-08-27 11:11:47,262 INFO [train_noCtc.py:878] (3/4) Epoch 22, batch 50, loss[loss=0.8155, simple_loss_common=0.4473, pruned_loss_common=0.2029, simple_loss_rich=0.3656, pruned_loss_rich=0.2062, over 14845.00 frames. utt_duration=131.4 frames, utt_pad_proportion=0.1988, over 457.00 utterances.], tot_loss[loss=0.7938, simple_loss_common=0.5203, pruned_loss_common=0.1969, simple_loss_rich=0.347, pruned_loss_rich=0.1633, over 812665.50 frames. utt_duration=563.2 frames, utt_pad_proportion=0.04691, over 5787.49 utterances.], batch size: 457, lr: 1.74e-03
2023-08-27 11:11:47,263 INFO [train_noCtc.py:878] (2/4) Epoch 22, batch 50, loss[loss=0.7092, simple_loss_common=0.4632, pruned_loss_common=0.1811, simple_loss_rich=0.3054, pruned_loss_rich=0.1438, over 18058.00 frames. utt_duration=1096 frames, utt_pad_proportion=0.02225, over 66.00 utterances.], tot_loss[loss=0.7933, simple_loss_common=0.5174, pruned_loss_common=0.1965, simple_loss_rich=0.346, pruned_loss_rich=0.1651, over 801834.16 frames. utt_duration=480.1 frames, utt_pad_proportion=0.08251, over 6701.31 utterances.], batch size: 66, lr: 1.74e-03
2023-08-27 11:11:47,263 INFO [train_noCtc.py:878] (1/4) Epoch 22, batch 50, loss[loss=0.6804, simple_loss_common=0.4437, pruned_loss_common=0.1702, simple_loss_rich=0.2944, pruned_loss_rich=0.1412, over 17978.00 frames. utt_duration=1161 frames, utt_pad_proportion=0.03138, over 62.00 utterances.], tot_loss[loss=0.8051, simple_loss_common=0.5193, pruned_loss_common=0.2021, simple_loss_rich=0.3488, pruned_loss_rich=0.1689, over 803600.04 frames. utt_duration=473.3 frames, utt_pad_proportion=0.07048, over 6812.44 utterances.], batch size: 62, lr: 1.74e-03
2023-08-27 11:11:47,266 INFO [train_noCtc.py:878] (0/4) Epoch 22, batch 50, loss[loss=0.8404, simple_loss_common=0.5113, pruned_loss_common=0.2208, simple_loss_rich=0.3547, pruned_loss_rich=0.1866, over 17410.00 frames. utt_duration=331.5 frames, utt_pad_proportion=0.06366, over 211.00 utterances.], tot_loss[loss=0.8074, simple_loss_common=0.5181, pruned_loss_common=0.2046, simple_loss_rich=0.3482, pruned_loss_rich=0.1696, over 799910.63 frames. utt_duration=455.8 frames, utt_pad_proportion=0.0733, over 7042.54 utterances.], batch size: 211, lr: 1.74e-03
2023-08-27 11:12:22,923 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/checkpoint-4000.pt
2023-08-27 11:13:04,151 INFO [train_noCtc.py:878] (3/4) Epoch 22, batch 100, loss[loss=0.9285, simple_loss_common=0.5381, pruned_loss_common=0.252, simple_loss_rich=0.38, pruned_loss_rich=0.2175, over 17404.00 frames. utt_duration=290.3 frames, utt_pad_proportion=0.06651, over 241.00 utterances.], tot_loss[loss=0.784, simple_loss_common=0.5141, pruned_loss_common=0.1937, simple_loss_rich=0.3444, pruned_loss_rich=0.1611, over 1426805.20 frames. utt_duration=537.1 frames, utt_pad_proportion=0.05318, over 10654.47 utterances.], batch size: 241, lr: 1.74e-03
2023-08-27 11:13:04,153 INFO [train_noCtc.py:878] (2/4) Epoch 22, batch 100, loss[loss=0.8308, simple_loss_common=0.5316, pruned_loss_common=0.2086, simple_loss_rich=0.3566, pruned_loss_rich=0.1781, over 18075.00 frames. utt_duration=557.7 frames, utt_pad_proportion=0.02677, over 130.00 utterances.], tot_loss[loss=0.7989, simple_loss_common=0.516, pruned_loss_common=0.1993, simple_loss_rich=0.3484, pruned_loss_rich=0.1674, over 1414370.81 frames. utt_duration=470 frames, utt_pad_proportion=0.07145, over 12073.61 utterances.], batch size: 130, lr: 1.74e-03
2023-08-27 11:13:04,154 INFO [train_noCtc.py:878] (1/4) Epoch 22, batch 100, loss[loss=0.8115, simple_loss_common=0.5226, pruned_loss_common=0.2028, simple_loss_rich=0.3518, pruned_loss_rich=0.1716, over 18026.00 frames. utt_duration=491.8 frames, utt_pad_proportion=0.0338, over 147.00 utterances.], tot_loss[loss=0.783, simple_loss_common=0.5119, pruned_loss_common=0.1935, simple_loss_rich=0.3438, pruned_loss_rich=0.1617, over 1419763.66 frames. utt_duration=503.8 frames, utt_pad_proportion=0.06896, over 11305.71 utterances.], batch size: 147, lr: 1.74e-03
2023-08-27 11:13:04,156 INFO [train_noCtc.py:878] (0/4) Epoch 22, batch 100, loss[loss=0.7151, simple_loss_common=0.49, pruned_loss_common=0.1704, simple_loss_rich=0.3207, pruned_loss_rich=0.1394, over 18221.00 frames. utt_duration=973.2 frames, utt_pad_proportion=0.01898, over 75.00 utterances.], tot_loss[loss=0.7795, simple_loss_common=0.5091, pruned_loss_common=0.1935, simple_loss_rich=0.3413, pruned_loss_rich=0.1607, over 1417938.30 frames. utt_duration=508.8 frames, utt_pad_proportion=0.06436, over 11179.93 utterances.], batch size: 75, lr: 1.74e-03
2023-08-27 11:14:09,382 INFO [train_noCtc.py:878] (3/4) Epoch 22, batch 150, loss[loss=0.6572, simple_loss_common=0.4442, pruned_loss_common=0.1565, simple_loss_rich=0.2952, pruned_loss_rich=0.1311, over 17962.00 frames. utt_duration=1160 frames, utt_pad_proportion=0.03306, over 62.00 utterances.], tot_loss[loss=0.7844, simple_loss_common=0.515, pruned_loss_common=0.1941, simple_loss_rich=0.3443, pruned_loss_rich=0.1606, over 1912048.89 frames. utt_duration=556.6 frames, utt_pad_proportion=0.04732, over 13777.03 utterances.], batch size: 62, lr: 1.73e-03
2023-08-27 11:14:09,383 INFO [train_noCtc.py:878] (1/4) Epoch 22, batch 150, loss[loss=0.7645, simple_loss_common=0.5191, pruned_loss_common=0.1816, simple_loss_rich=0.3474, pruned_loss_rich=0.1497, over 18392.00 frames. utt_duration=695.3 frames, utt_pad_proportion=0.01648, over 106.00 utterances.], tot_loss[loss=0.7924, simple_loss_common=0.5162, pruned_loss_common=0.1976, simple_loss_rich=0.3461, pruned_loss_rich=0.1638, over 1896483.05 frames. utt_duration=500.4 frames, utt_pad_proportion=0.06804, over 15205.83 utterances.], batch size: 106, lr: 1.73e-03
2023-08-27 11:14:09,384 INFO [train_noCtc.py:878] (2/4) Epoch 22, batch 150, loss[loss=0.7019, simple_loss_common=0.4875, pruned_loss_common=0.1594, simple_loss_rich=0.3218, pruned_loss_rich=0.1379, over 18361.00 frames. utt_duration=908.2 frames, utt_pad_proportion=0.01606, over 81.00 utterances.], tot_loss[loss=0.7982, simple_loss_common=0.515, pruned_loss_common=0.1998, simple_loss_rich=0.3475, pruned_loss_rich=0.1671, over 1889287.92 frames. utt_duration=471.9 frames, utt_pad_proportion=0.07263, over 16063.91 utterances.], batch size: 81, lr: 1.73e-03
2023-08-27 11:14:09,387 INFO [train_noCtc.py:878] (0/4) Epoch 22, batch 150, loss[loss=0.8843, simple_loss_common=0.4737, pruned_loss_common=0.2283, simple_loss_rich=0.388, pruned_loss_rich=0.2251, over 14818.00 frames. utt_duration=131 frames, utt_pad_proportion=0.201, over 457.00 utterances.], tot_loss[loss=0.7825, simple_loss_common=0.5083, pruned_loss_common=0.1945, simple_loss_rich=0.3428, pruned_loss_rich=0.1624, over 1883585.10 frames. utt_duration=472.1 frames, utt_pad_proportion=0.0825, over 16010.85 utterances.], batch size: 457, lr: 1.73e-03
2023-08-27 11:14:53,171 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-22.pt
2023-08-27 11:15:13,464 INFO [train_noCtc.py:878] (3/4) Epoch 23, batch 0, loss[loss=0.8168, simple_loss_common=0.4551, pruned_loss_common=0.1999, simple_loss_rich=0.3692, pruned_loss_rich=0.2048, over 14703.00 frames. utt_duration=130.2 frames, utt_pad_proportion=0.2063, over 457.00 utterances.], tot_loss[loss=0.8168, simple_loss_common=0.4551, pruned_loss_common=0.1999, simple_loss_rich=0.3692, pruned_loss_rich=0.2048, over 14703.00 frames. utt_duration=130.2 frames, utt_pad_proportion=0.2063, over 457.00 utterances.], batch size: 457, lr: 1.70e-03
2023-08-27 11:15:13,465 INFO [train_noCtc.py:878] (1/4) Epoch 23, batch 0, loss[loss=0.8358, simple_loss_common=0.5078, pruned_loss_common=0.2193, simple_loss_rich=0.3548, pruned_loss_rich=0.1852, over 17521.00 frames. utt_duration=332.1 frames, utt_pad_proportion=0.06184, over 212.00 utterances.], tot_loss[loss=0.8358, simple_loss_common=0.5078, pruned_loss_common=0.2193, simple_loss_rich=0.3548, pruned_loss_rich=0.1852, over 17521.00 frames. utt_duration=332.1 frames, utt_pad_proportion=0.06184, over 212.00 utterances.], batch size: 212, lr: 1.70e-03
2023-08-27 11:15:13,466 INFO [train_noCtc.py:878] (2/4) Epoch 23, batch 0, loss[loss=0.8101, simple_loss_common=0.521, pruned_loss_common=0.2024, simple_loss_rich=0.3564, pruned_loss_rich=0.169, over 17831.00 frames. utt_duration=455.9 frames, utt_pad_proportion=0.04015, over 157.00 utterances.], tot_loss[loss=0.8101, simple_loss_common=0.521, pruned_loss_common=0.2024, simple_loss_rich=0.3564, pruned_loss_rich=0.169, over 17831.00 frames. utt_duration=455.9 frames, utt_pad_proportion=0.04015, over 157.00 utterances.], batch size: 157, lr: 1.70e-03
2023-08-27 11:15:13,467 INFO [train_noCtc.py:878] (0/4) Epoch 23, batch 0, loss[loss=0.6776, simple_loss_common=0.4496, pruned_loss_common=0.1653, simple_loss_rich=0.2995, pruned_loss_rich=0.1378, over 18000.00 frames. utt_duration=1163 frames, utt_pad_proportion=0.03033, over 62.00 utterances.], tot_loss[loss=0.6776, simple_loss_common=0.4496, pruned_loss_common=0.1653, simple_loss_rich=0.2995, pruned_loss_rich=0.1378, over 18000.00 frames. utt_duration=1163 frames, utt_pad_proportion=0.03033, over 62.00 utterances.], batch size: 62, lr: 1.70e-03
2023-08-27 11:16:25,989 INFO [train_noCtc.py:878] (3/4) Epoch 23, batch 50, loss[loss=0.9919, simple_loss_common=0.534, pruned_loss_common=0.2955, simple_loss_rich=0.3808, pruned_loss_rich=0.239, over 16038.00 frames. utt_duration=190.7 frames, utt_pad_proportion=0.1371, over 339.00 utterances.], tot_loss[loss=0.841, simple_loss_common=0.5328, pruned_loss_common=0.2195, simple_loss_rich=0.3552, pruned_loss_rich=0.1774, over 803662.87 frames. utt_duration=470.4 frames, utt_pad_proportion=0.06373, over 6855.28 utterances.], batch size: 339, lr: 1.69e-03
2023-08-27 11:16:25,991 INFO [train_noCtc.py:878] (2/4) Epoch 23, batch 50, loss[loss=0.7646, simple_loss_common=0.5047, pruned_loss_common=0.1847, simple_loss_rich=0.344, pruned_loss_rich=0.1556, over 17867.00 frames. utt_duration=456.8 frames, utt_pad_proportion=0.03832, over 157.00 utterances.], tot_loss[loss=0.8262, simple_loss_common=0.5254, pruned_loss_common=0.2131, simple_loss_rich=0.3524, pruned_loss_rich=0.1742, over 801443.88 frames. utt_duration=460.2 frames, utt_pad_proportion=0.07563, over 6988.94 utterances.], batch size: 157, lr: 1.69e-03
2023-08-27 11:16:25,992 INFO [train_noCtc.py:878] (0/4) Epoch 23, batch 50, loss[loss=0.683, simple_loss_common=0.4539, pruned_loss_common=0.1646, simple_loss_rich=0.3062, pruned_loss_rich=0.1383, over 17902.00 frames. utt_duration=1156 frames, utt_pad_proportion=0.03315, over 62.00 utterances.], tot_loss[loss=0.8377, simple_loss_common=0.5335, pruned_loss_common=0.2177, simple_loss_rich=0.3558, pruned_loss_rich=0.1754, over 807489.30 frames. utt_duration=503.1 frames, utt_pad_proportion=0.05864, over 6438.54 utterances.], batch size: 62, lr: 1.69e-03
2023-08-27 11:16:25,992 INFO [train_noCtc.py:878] (1/4) Epoch 23, batch 50, loss[loss=0.718, simple_loss_common=0.5078, pruned_loss_common=0.1632, simple_loss_rich=0.3312, pruned_loss_rich=0.1354, over 18275.00 frames. utt_duration=851.9 frames, utt_pad_proportion=0.01405, over 86.00 utterances.], tot_loss[loss=0.8151, simple_loss_common=0.5241, pruned_loss_common=0.2093, simple_loss_rich=0.3493, pruned_loss_rich=0.1691, over 806368.85 frames. utt_duration=512.3 frames, utt_pad_proportion=0.06573, over 6314.54 utterances.], batch size: 86, lr: 1.69e-03
2023-08-27 11:17:42,399 INFO [train_noCtc.py:878] (3/4) Epoch 23, batch 100, loss[loss=0.7192, simple_loss_common=0.4766, pruned_loss_common=0.181, simple_loss_rich=0.3113, pruned_loss_rich=0.1442, over 18052.00 frames. utt_duration=1096 frames, utt_pad_proportion=0.02354, over 66.00 utterances.], tot_loss[loss=0.8058, simple_loss_common=0.5201, pruned_loss_common=0.2043, simple_loss_rich=0.3484, pruned_loss_rich=0.1673, over 1416386.93 frames. utt_duration=480.1 frames, utt_pad_proportion=0.06706, over 11838.42 utterances.], batch size: 66, lr: 1.69e-03
2023-08-27 11:17:42,400 INFO [train_noCtc.py:878] (0/4) Epoch 23, batch 100, loss[loss=0.8585, simple_loss_common=0.5594, pruned_loss_common=0.219, simple_loss_rich=0.3665, pruned_loss_rich=0.1765, over 18301.00 frames. utt_duration=643.6 frames, utt_pad_proportion=0.02044, over 114.00 utterances.], tot_loss[loss=0.7943, simple_loss_common=0.518, pruned_loss_common=0.1989, simple_loss_rich=0.3467, pruned_loss_rich=0.1631, over 1423031.47 frames. utt_duration=515.7 frames, utt_pad_proportion=0.06259, over 11069.13 utterances.], batch size: 114, lr: 1.69e-03
2023-08-27 11:17:42,402 INFO [train_noCtc.py:878] (2/4) Epoch 23, batch 100, loss[loss=0.9008, simple_loss_common=0.5615, pruned_loss_common=0.2432, simple_loss_rich=0.3732, pruned_loss_rich=0.1903, over 18198.00 frames. utt_duration=557.2 frames, utt_pad_proportion=0.02596, over 131.00 utterances.], tot_loss[loss=0.8033, simple_loss_common=0.5202, pruned_loss_common=0.2021, simple_loss_rich=0.3492, pruned_loss_rich=0.1665, over 1417883.90 frames. utt_duration=481.6 frames, utt_pad_proportion=0.06426, over 11811.26 utterances.], batch size: 131, lr: 1.69e-03
2023-08-27 11:17:42,403 INFO [train_noCtc.py:878] (1/4) Epoch 23, batch 100, loss[loss=0.8436, simple_loss_common=0.5547, pruned_loss_common=0.214, simple_loss_rich=0.3618, pruned_loss_rich=0.1713, over 18332.00 frames. utt_duration=825.2 frames, utt_pad_proportion=0.01531, over 89.00 utterances.], tot_loss[loss=0.7979, simple_loss_common=0.5173, pruned_loss_common=0.2014, simple_loss_rich=0.3466, pruned_loss_rich=0.1645, over 1417137.60 frames. utt_duration=493.4 frames, utt_pad_proportion=0.06917, over 11523.70 utterances.], batch size: 89, lr: 1.69e-03
2023-08-27 11:18:52,809 INFO [train_noCtc.py:878] (3/4) Epoch 23, batch 150, loss[loss=0.6746, simple_loss_common=0.4677, pruned_loss_common=0.1569, simple_loss_rich=0.3055, pruned_loss_rich=0.1311, over 18413.00 frames. utt_duration=1010 frames, utt_pad_proportion=0.01633, over 73.00 utterances.], tot_loss[loss=0.7949, simple_loss_common=0.5156, pruned_loss_common=0.1991, simple_loss_rich=0.3466, pruned_loss_rich=0.1647, over 1891525.36 frames. utt_duration=473.1 frames, utt_pad_proportion=0.06817, over 16041.86 utterances.], batch size: 73, lr: 1.68e-03
2023-08-27 11:18:52,809 INFO [train_noCtc.py:878] (0/4) Epoch 23, batch 150, loss[loss=0.7396, simple_loss_common=0.524, pruned_loss_common=0.162, simple_loss_rich=0.3512, pruned_loss_rich=0.1401, over 18082.00 frames. utt_duration=557.9 frames, utt_pad_proportion=0.02638, over 130.00 utterances.], tot_loss[loss=0.776, simple_loss_common=0.5114, pruned_loss_common=0.1911, simple_loss_rich=0.3423, pruned_loss_rich=0.158, over 1904651.52 frames. utt_duration=542.2 frames, utt_pad_proportion=0.06132, over 14089.25 utterances.], batch size: 130, lr: 1.68e-03
2023-08-27 11:18:52,810 INFO [train_noCtc.py:878] (1/4) Epoch 23, batch 150, loss[loss=0.8358, simple_loss_common=0.5447, pruned_loss_common=0.2112, simple_loss_rich=0.3628, pruned_loss_rich=0.1709, over 18272.00 frames. utt_duration=642.8 frames, utt_pad_proportion=0.02162, over 114.00 utterances.], tot_loss[loss=0.7825, simple_loss_common=0.5114, pruned_loss_common=0.1946, simple_loss_rich=0.3432, pruned_loss_rich=0.1606, over 1898234.79 frames. utt_duration=510.7 frames, utt_pad_proportion=0.06297, over 14910.60 utterances.], batch size: 114, lr: 1.68e-03
2023-08-27 11:18:52,811 INFO [train_noCtc.py:878] (2/4) Epoch 23, batch 150, loss[loss=0.6678, simple_loss_common=0.4821, pruned_loss_common=0.1473, simple_loss_rich=0.311, pruned_loss_rich=0.124, over 18311.00 frames. utt_duration=940.7 frames, utt_pad_proportion=0.01399, over 78.00 utterances.], tot_loss[loss=0.7881, simple_loss_common=0.513, pruned_loss_common=0.196, simple_loss_rich=0.3452, pruned_loss_rich=0.163, over 1890224.76 frames. utt_duration=476.4 frames, utt_pad_proportion=0.07298, over 15918.66 utterances.], batch size: 78, lr: 1.68e-03
2023-08-27 11:19:35,546 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-23.pt
2023-08-27 11:19:55,436 INFO [train_noCtc.py:878] (1/4) Epoch 24, batch 0, loss[loss=0.684, simple_loss_common=0.4796, pruned_loss_common=0.153, simple_loss_rich=0.3192, pruned_loss_rich=0.1316, over 18268.00 frames. utt_duration=938.2 frames, utt_pad_proportion=0.01658, over 78.00 utterances.], tot_loss[loss=0.684, simple_loss_common=0.4796, pruned_loss_common=0.153, simple_loss_rich=0.3192, pruned_loss_rich=0.1316, over 18268.00 frames. utt_duration=938.2 frames, utt_pad_proportion=0.01658, over 78.00 utterances.], batch size: 78, lr: 1.65e-03
2023-08-27 11:19:55,436 INFO [train_noCtc.py:878] (3/4) Epoch 24, batch 0, loss[loss=0.6903, simple_loss_common=0.466, pruned_loss_common=0.1659, simple_loss_rich=0.3091, pruned_loss_rich=0.1369, over 18043.00 frames. utt_duration=1095 frames, utt_pad_proportion=0.024, over 66.00 utterances.], tot_loss[loss=0.6903, simple_loss_common=0.466, pruned_loss_common=0.1659, simple_loss_rich=0.3091, pruned_loss_rich=0.1369, over 18043.00 frames. utt_duration=1095 frames, utt_pad_proportion=0.024, over 66.00 utterances.], batch size: 66, lr: 1.65e-03
2023-08-27 11:19:55,437 INFO [train_noCtc.py:878] (2/4) Epoch 24, batch 0, loss[loss=0.7893, simple_loss_common=0.5163, pruned_loss_common=0.1874, simple_loss_rich=0.3537, pruned_loss_rich=0.167, over 18060.00 frames. utt_duration=525 frames, utt_pad_proportion=0.03133, over 138.00 utterances.], tot_loss[loss=0.7893, simple_loss_common=0.5163, pruned_loss_common=0.1874, simple_loss_rich=0.3537, pruned_loss_rich=0.167, over 18060.00 frames. utt_duration=525 frames, utt_pad_proportion=0.03133, over 138.00 utterances.], batch size: 138, lr: 1.65e-03
2023-08-27 11:19:55,438 INFO [train_noCtc.py:878] (0/4) Epoch 24, batch 0, loss[loss=0.6533, simple_loss_common=0.4371, pruned_loss_common=0.1609, simple_loss_rich=0.2921, pruned_loss_rich=0.1278, over 17942.00 frames. utt_duration=1159 frames, utt_pad_proportion=0.03339, over 62.00 utterances.], tot_loss[loss=0.6533, simple_loss_common=0.4371, pruned_loss_common=0.1609, simple_loss_rich=0.2921, pruned_loss_rich=0.1278, over 17942.00 frames. utt_duration=1159 frames, utt_pad_proportion=0.03339, over 62.00 utterances.], batch size: 62, lr: 1.65e-03
2023-08-27 11:21:07,995 INFO [train_noCtc.py:878] (3/4) Epoch 24, batch 50, loss[loss=0.6329, simple_loss_common=0.4398, pruned_loss_common=0.152, simple_loss_rich=0.2821, pruned_loss_rich=0.1199, over 17920.00 frames. utt_duration=1158 frames, utt_pad_proportion=0.03512, over 62.00 utterances.], tot_loss[loss=0.7479, simple_loss_common=0.5024, pruned_loss_common=0.1789, simple_loss_rich=0.3364, pruned_loss_rich=0.1496, over 809181.73 frames. utt_duration=538.3 frames, utt_pad_proportion=0.05443, over 6029.81 utterances.], batch size: 62, lr: 1.65e-03
2023-08-27 11:21:07,996 INFO [train_noCtc.py:878] (1/4) Epoch 24, batch 50, loss[loss=0.8192, simple_loss_common=0.4513, pruned_loss_common=0.211, simple_loss_rich=0.3583, pruned_loss_rich=0.2034, over 14812.00 frames. utt_duration=131.2 frames, utt_pad_proportion=0.2001, over 457.00 utterances.], tot_loss[loss=0.7704, simple_loss_common=0.5046, pruned_loss_common=0.188, simple_loss_rich=0.3433, pruned_loss_rich=0.1584, over 798448.37 frames. utt_duration=432.2 frames, utt_pad_proportion=0.08551, over 7414.79 utterances.], batch size: 457, lr: 1.65e-03
2023-08-27 11:21:07,996 INFO [train_noCtc.py:878] (0/4) Epoch 24, batch 50, loss[loss=0.7423, simple_loss_common=0.5145, pruned_loss_common=0.1681, simple_loss_rich=0.3462, pruned_loss_rich=0.1438, over 18363.00 frames. utt_duration=721.6 frames, utt_pad_proportion=0.01556, over 102.00 utterances.], tot_loss[loss=0.7557, simple_loss_common=0.5018, pruned_loss_common=0.1836, simple_loss_rich=0.337, pruned_loss_rich=0.1526, over 808943.12 frames. utt_duration=527.9 frames, utt_pad_proportion=0.0509, over 6146.79 utterances.], batch size: 102, lr: 1.65e-03
2023-08-27 11:21:07,997 INFO [train_noCtc.py:878] (2/4) Epoch 24, batch 50, loss[loss=0.8521, simple_loss_common=0.5414, pruned_loss_common=0.2187, simple_loss_rich=0.3656, pruned_loss_rich=0.1798, over 17750.00 frames. utt_duration=375.3 frames, utt_pad_proportion=0.04748, over 190.00 utterances.], tot_loss[loss=0.752, simple_loss_common=0.498, pruned_loss_common=0.1817, simple_loss_rich=0.3375, pruned_loss_rich=0.1526, over 798515.63 frames. utt_duration=441.2 frames, utt_pad_proportion=0.08822, over 7263.48 utterances.], batch size: 190, lr: 1.65e-03
2023-08-27 11:22:23,442 INFO [train_noCtc.py:878] (3/4) Epoch 24, batch 100, loss[loss=0.7362, simple_loss_common=0.5213, pruned_loss_common=0.1648, simple_loss_rich=0.3425, pruned_loss_rich=0.1395, over 18323.00 frames. utt_duration=719.9 frames, utt_pad_proportion=0.01787, over 102.00 utterances.], tot_loss[loss=0.7505, simple_loss_common=0.5024, pruned_loss_common=0.1803, simple_loss_rich=0.3373, pruned_loss_rich=0.1504, over 1421959.33 frames. utt_duration=518.4 frames, utt_pad_proportion=0.06412, over 11003.73 utterances.], batch size: 102, lr: 1.64e-03
2023-08-27 11:22:23,443 INFO [train_noCtc.py:878] (1/4) Epoch 24, batch 100, loss[loss=0.7429, simple_loss_common=0.5002, pruned_loss_common=0.1703, simple_loss_rich=0.3457, pruned_loss_rich=0.1497, over 18217.00 frames. utt_duration=670 frames, utt_pad_proportion=0.01898, over 109.00 utterances.], tot_loss[loss=0.7585, simple_loss_common=0.5018, pruned_loss_common=0.1847, simple_loss_rich=0.338, pruned_loss_rich=0.1539, over 1416317.61 frames. utt_duration=490 frames, utt_pad_proportion=0.07112, over 11597.82 utterances.], batch size: 109, lr: 1.64e-03
2023-08-27 11:22:23,446 INFO [train_noCtc.py:878] (2/4) Epoch 24, batch 100, loss[loss=0.6434, simple_loss_common=0.4564, pruned_loss_common=0.1481, simple_loss_rich=0.2974, pruned_loss_rich=0.1184, over 18365.00 frames. utt_duration=1051 frames, utt_pad_proportion=0.0179, over 70.00 utterances.], tot_loss[loss=0.7635, simple_loss_common=0.5028, pruned_loss_common=0.187, simple_loss_rich=0.3397, pruned_loss_rich=0.1553, over 1413130.25 frames. utt_duration=464.3 frames, utt_pad_proportion=0.07194, over 12212.81 utterances.], batch size: 70, lr: 1.64e-03
2023-08-27 11:22:23,447 INFO [train_noCtc.py:878] (0/4) Epoch 24, batch 100, loss[loss=0.8212, simple_loss_common=0.4598, pruned_loss_common=0.2054, simple_loss_rich=0.3702, pruned_loss_rich=0.2008, over 14835.00 frames. utt_duration=131.3 frames, utt_pad_proportion=0.1994, over 457.00 utterances.], tot_loss[loss=0.7572, simple_loss_common=0.5037, pruned_loss_common=0.1842, simple_loss_rich=0.3377, pruned_loss_rich=0.1523, over 1421705.68 frames. utt_duration=518.8 frames, utt_pad_proportion=0.06345, over 10993.25 utterances.], batch size: 457, lr: 1.64e-03
2023-08-27 11:23:33,634 INFO [train_noCtc.py:878] (1/4) Epoch 24, batch 150, loss[loss=0.756, simple_loss_common=0.5244, pruned_loss_common=0.1749, simple_loss_rich=0.3414, pruned_loss_rich=0.1482, over 18308.00 frames. utt_duration=643.8 frames, utt_pad_proportion=0.02011, over 114.00 utterances.], tot_loss[loss=0.7597, simple_loss_common=0.5018, pruned_loss_common=0.1854, simple_loss_rich=0.3381, pruned_loss_rich=0.1544, over 1895065.09 frames. utt_duration=496.1 frames, utt_pad_proportion=0.06466, over 15324.40 utterances.], batch size: 114, lr: 1.64e-03
2023-08-27 11:23:33,634 INFO [train_noCtc.py:878] (0/4) Epoch 24, batch 150, loss[loss=0.63, simple_loss_common=0.4778, pruned_loss_common=0.1297, simple_loss_rich=0.3037, pruned_loss_rich=0.1096, over 18274.00 frames. utt_duration=938.8 frames, utt_pad_proportion=0.01597, over 78.00 utterances.], tot_loss[loss=0.7525, simple_loss_common=0.5013, pruned_loss_common=0.1823, simple_loss_rich=0.3363, pruned_loss_rich=0.1514, over 1901951.12 frames. utt_duration=524 frames, utt_pad_proportion=0.05953, over 14559.28 utterances.], batch size: 78, lr: 1.64e-03
2023-08-27 11:23:33,634 INFO [train_noCtc.py:878] (2/4) Epoch 24, batch 150, loss[loss=0.7669, simple_loss_common=0.529, pruned_loss_common=0.1737, simple_loss_rich=0.3506, pruned_loss_rich=0.1534, over 18256.00 frames. utt_duration=615.2 frames, utt_pad_proportion=0.022, over 119.00 utterances.], tot_loss[loss=0.7595, simple_loss_common=0.5008, pruned_loss_common=0.1852, simple_loss_rich=0.3384, pruned_loss_rich=0.1547, over 1887562.86 frames. utt_duration=467.6 frames, utt_pad_proportion=0.0727, over 16198.22 utterances.], batch size: 119, lr: 1.64e-03
2023-08-27 11:23:33,634 INFO [train_noCtc.py:878] (3/4) Epoch 24, batch 150, loss[loss=0.7914, simple_loss_common=0.4937, pruned_loss_common=0.1981, simple_loss_rich=0.3432, pruned_loss_rich=0.1749, over 17534.00 frames. utt_duration=332.3 frames, utt_pad_proportion=0.05867, over 212.00 utterances.], tot_loss[loss=0.7498, simple_loss_common=0.5, pruned_loss_common=0.1804, simple_loss_rich=0.3366, pruned_loss_rich=0.1511, over 1893172.06 frames. utt_duration=497.3 frames, utt_pad_proportion=0.07245, over 15274.08 utterances.], batch size: 212, lr: 1.64e-03
2023-08-27 11:24:15,750 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-24.pt
2023-08-27 11:24:35,993 INFO [train_noCtc.py:878] (3/4) Epoch 25, batch 0, loss[loss=0.7656, simple_loss_common=0.5271, pruned_loss_common=0.1731, simple_loss_rich=0.3527, pruned_loss_rich=0.1526, over 18253.00 frames. utt_duration=770 frames, utt_pad_proportion=0.01782, over 95.00 utterances.], tot_loss[loss=0.7656, simple_loss_common=0.5271, pruned_loss_common=0.1731, simple_loss_rich=0.3527, pruned_loss_rich=0.1526, over 18253.00 frames. utt_duration=770 frames, utt_pad_proportion=0.01782, over 95.00 utterances.], batch size: 95, lr: 1.60e-03
2023-08-27 11:24:35,995 INFO [train_noCtc.py:878] (0/4) Epoch 25, batch 0, loss[loss=0.6492, simple_loss_common=0.4725, pruned_loss_common=0.1325, simple_loss_rich=0.3196, pruned_loss_rich=0.1206, over 18212.00 frames. utt_duration=879.3 frames, utt_pad_proportion=0.01751, over 83.00 utterances.], tot_loss[loss=0.6492, simple_loss_common=0.4725, pruned_loss_common=0.1325, simple_loss_rich=0.3196, pruned_loss_rich=0.1206, over 18212.00 frames. utt_duration=879.3 frames, utt_pad_proportion=0.01751, over 83.00 utterances.], batch size: 83, lr: 1.60e-03
2023-08-27 11:24:35,995 INFO [train_noCtc.py:878] (1/4) Epoch 25, batch 0, loss[loss=0.7086, simple_loss_common=0.4877, pruned_loss_common=0.1551, simple_loss_rich=0.3358, pruned_loss_rich=0.1418, over 18281.00 frames. utt_duration=616 frames, utt_pad_proportion=0.02064, over 119.00 utterances.], tot_loss[loss=0.7086, simple_loss_common=0.4877, pruned_loss_common=0.1551, simple_loss_rich=0.3358, pruned_loss_rich=0.1418, over 18281.00 frames. utt_duration=616 frames, utt_pad_proportion=0.02064, over 119.00 utterances.], batch size: 119, lr: 1.60e-03
2023-08-27 11:24:35,996 INFO [train_noCtc.py:878] (2/4) Epoch 25, batch 0, loss[loss=0.5862, simple_loss_common=0.4327, pruned_loss_common=0.1174, simple_loss_rich=0.2904, pruned_loss_rich=0.1072, over 18425.00 frames. utt_duration=1011 frames, utt_pad_proportion=0.01553, over 73.00 utterances.], tot_loss[loss=0.5862, simple_loss_common=0.4327, pruned_loss_common=0.1174, simple_loss_rich=0.2904, pruned_loss_rich=0.1072, over 18425.00 frames. utt_duration=1011 frames, utt_pad_proportion=0.01553, over 73.00 utterances.], batch size: 73, lr: 1.60e-03
2023-08-27 11:25:46,864 INFO [train_noCtc.py:878] (3/4) Epoch 25, batch 50, loss[loss=0.7072, simple_loss_common=0.4865, pruned_loss_common=0.1625, simple_loss_rich=0.329, pruned_loss_rich=0.1369, over 18335.00 frames. utt_duration=720.4 frames, utt_pad_proportion=0.01723, over 102.00 utterances.], tot_loss[loss=0.7804, simple_loss_common=0.5126, pruned_loss_common=0.1962, simple_loss_rich=0.3407, pruned_loss_rich=0.1576, over 808314.29 frames. utt_duration=528.5 frames, utt_pad_proportion=0.0596, over 6135.42 utterances.], batch size: 102, lr: 1.60e-03
2023-08-27 11:25:46,864 INFO [train_noCtc.py:878] (2/4) Epoch 25, batch 50, loss[loss=0.6173, simple_loss_common=0.4425, pruned_loss_common=0.1424, simple_loss_rich=0.2823, pruned_loss_rich=0.1124, over 18007.00 frames. utt_duration=1093 frames, utt_pad_proportion=0.02593, over 66.00 utterances.], tot_loss[loss=0.7768, simple_loss_common=0.5133, pruned_loss_common=0.1933, simple_loss_rich=0.3404, pruned_loss_rich=0.1566, over 810151.27 frames. utt_duration=548.3 frames, utt_pad_proportion=0.05857, over 5926.55 utterances.], batch size: 66, lr: 1.60e-03
2023-08-27 11:25:46,865 INFO [train_noCtc.py:878] (0/4) Epoch 25, batch 50, loss[loss=0.6938, simple_loss_common=0.4991, pruned_loss_common=0.1564, simple_loss_rich=0.3241, pruned_loss_rich=0.1259, over 18282.00 frames. utt_duration=771 frames, utt_pad_proportion=0.01657, over 95.00 utterances.], tot_loss[loss=0.7784, simple_loss_common=0.5106, pruned_loss_common=0.1945, simple_loss_rich=0.3407, pruned_loss_rich=0.1582, over 803829.06 frames. utt_duration=482.4 frames, utt_pad_proportion=0.07276, over 6686.07 utterances.], batch size: 95, lr: 1.60e-03
2023-08-27 11:25:46,865 INFO [train_noCtc.py:878] (1/4) Epoch 25, batch 50, loss[loss=0.6907, simple_loss_common=0.4871, pruned_loss_common=0.1557, simple_loss_rich=0.3212, pruned_loss_rich=0.1308, over 18326.00 frames. utt_duration=798.2 frames, utt_pad_proportion=0.017, over 92.00 utterances.], tot_loss[loss=0.7901, simple_loss_common=0.5118, pruned_loss_common=0.1997, simple_loss_rich=0.3437, pruned_loss_rich=0.1627, over 802794.29 frames. utt_duration=472.9 frames, utt_pad_proportion=0.06768, over 6811.33 utterances.], batch size: 92, lr: 1.60e-03
2023-08-27 11:26:58,741 INFO [train_noCtc.py:878] (3/4) Epoch 25, batch 100, loss[loss=0.7766, simple_loss_common=0.5456, pruned_loss_common=0.1817, simple_loss_rich=0.3521, pruned_loss_rich=0.146, over 18126.00 frames. utt_duration=526.9 frames, utt_pad_proportion=0.02782, over 138.00 utterances.], tot_loss[loss=0.7754, simple_loss_common=0.5133, pruned_loss_common=0.1915, simple_loss_rich=0.3409, pruned_loss_rich=0.1568, over 1414028.26 frames. utt_duration=480.3 frames, utt_pad_proportion=0.07317, over 11812.81 utterances.], batch size: 138, lr: 1.60e-03
2023-08-27 11:26:58,742 INFO [train_noCtc.py:878] (2/4) Epoch 25, batch 100, loss[loss=0.6833, simple_loss_common=0.5077, pruned_loss_common=0.143, simple_loss_rich=0.3284, pruned_loss_rich=0.1223, over 18349.00 frames. utt_duration=826.1 frames, utt_pad_proportion=0.01425, over 89.00 utterances.], tot_loss[loss=0.7703, simple_loss_common=0.5201, pruned_loss_common=0.1878, simple_loss_rich=0.3404, pruned_loss_rich=0.1523, over 1432527.19 frames. utt_duration=581.8 frames, utt_pad_proportion=0.05036, over 9874.59 utterances.], batch size: 89, lr: 1.60e-03
2023-08-27 11:26:58,743 INFO [train_noCtc.py:878] (1/4) Epoch 25, batch 100, loss[loss=0.7645, simple_loss_common=0.5253, pruned_loss_common=0.1808, simple_loss_rich=0.3417, pruned_loss_rich=0.1502, over 18059.00 frames. utt_duration=492.8 frames, utt_pad_proportion=0.0319, over 147.00 utterances.], tot_loss[loss=0.7759, simple_loss_common=0.5123, pruned_loss_common=0.1919, simple_loss_rich=0.3405, pruned_loss_rich=0.1575, over 1416610.41 frames. utt_duration=488.2 frames, utt_pad_proportion=0.06708, over 11642.39 utterances.], batch size: 147, lr: 1.60e-03
2023-08-27 11:26:58,744 INFO [train_noCtc.py:878] (0/4) Epoch 25, batch 100, loss[loss=0.717, simple_loss_common=0.5274, pruned_loss_common=0.1484, simple_loss_rich=0.3464, pruned_loss_rich=0.1317, over 18411.00 frames. utt_duration=696.3 frames, utt_pad_proportion=0.01515, over 106.00 utterances.], tot_loss[loss=0.7705, simple_loss_common=0.5153, pruned_loss_common=0.1893, simple_loss_rich=0.3394, pruned_loss_rich=0.1538, over 1424081.25 frames. utt_duration=525.5 frames, utt_pad_proportion=0.05597, over 10870.99 utterances.], batch size: 106, lr: 1.60e-03
2023-08-27 11:28:08,061 INFO [train_noCtc.py:878] (3/4) Epoch 25, batch 150, loss[loss=0.6847, simple_loss_common=0.4792, pruned_loss_common=0.1688, simple_loss_rich=0.3007, pruned_loss_rich=0.126, over 17948.00 frames. utt_duration=1159 frames, utt_pad_proportion=0.03395, over 62.00 utterances.], tot_loss[loss=0.7791, simple_loss_common=0.5123, pruned_loss_common=0.1934, simple_loss_rich=0.3412, pruned_loss_rich=0.1588, over 1885080.04 frames. utt_duration=463.8 frames, utt_pad_proportion=0.07579, over 16310.52 utterances.], batch size: 62, lr: 1.59e-03
2023-08-27 11:28:08,061 INFO [train_noCtc.py:878] (1/4) Epoch 25, batch 150, loss[loss=0.7394, simple_loss_common=0.5274, pruned_loss_common=0.1904, simple_loss_rich=0.3043, pruned_loss_rich=0.1332, over 18030.00 frames. utt_duration=1094 frames, utt_pad_proportion=0.02485, over 66.00 utterances.], tot_loss[loss=0.7812, simple_loss_common=0.5143, pruned_loss_common=0.1942, simple_loss_rich=0.3416, pruned_loss_rich=0.1591, over 1891520.01 frames. utt_duration=477.3 frames, utt_pad_proportion=0.06807, over 15900.97 utterances.], batch size: 66, lr: 1.59e-03
2023-08-27 11:28:08,062 INFO [train_noCtc.py:878] (0/4) Epoch 25, batch 150, loss[loss=0.7552, simple_loss_common=0.5316, pruned_loss_common=0.1836, simple_loss_rich=0.333, pruned_loss_rich=0.1393, over 18354.00 frames. utt_duration=907.9 frames, utt_pad_proportion=0.01744, over 81.00 utterances.], tot_loss[loss=0.7686, simple_loss_common=0.5161, pruned_loss_common=0.1879, simple_loss_rich=0.3395, pruned_loss_rich=0.1528, over 1904303.13 frames. utt_duration=532 frames, utt_pad_proportion=0.05996, over 14356.65 utterances.], batch size: 81, lr: 1.59e-03
2023-08-27 11:28:08,062 INFO [train_noCtc.py:878] (2/4) Epoch 25, batch 150, loss[loss=0.9276, simple_loss_common=0.5444, pruned_loss_common=0.2547, simple_loss_rich=0.3841, pruned_loss_rich=0.2087, over 16992.00 frames. utt_duration=245.9 frames, utt_pad_proportion=0.08574, over 278.00 utterances.], tot_loss[loss=0.7703, simple_loss_common=0.518, pruned_loss_common=0.1882, simple_loss_rich=0.3401, pruned_loss_rich=0.1531, over 1910092.74 frames. utt_duration=561.4 frames, utt_pad_proportion=0.05509, over 13645.50 utterances.], batch size: 278, lr: 1.59e-03
2023-08-27 11:28:50,255 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-25.pt
2023-08-27 11:29:10,298 INFO [train_noCtc.py:878] (3/4) Epoch 26, batch 0, loss[loss=0.8027, simple_loss_common=0.5173, pruned_loss_common=0.2123, simple_loss_rich=0.3333, pruned_loss_rich=0.1651, over 18305.00 frames. utt_duration=1047 frames, utt_pad_proportion=0.02209, over 70.00 utterances.], tot_loss[loss=0.8027, simple_loss_common=0.5173, pruned_loss_common=0.2123, simple_loss_rich=0.3333, pruned_loss_rich=0.1651, over 18305.00 frames. utt_duration=1047 frames, utt_pad_proportion=0.02209, over 70.00 utterances.], batch size: 70, lr: 1.56e-03
2023-08-27 11:29:10,299 INFO [train_noCtc.py:878] (0/4) Epoch 26, batch 0, loss[loss=0.8913, simple_loss_common=0.5808, pruned_loss_common=0.2317, simple_loss_rich=0.3729, pruned_loss_rich=0.1827, over 18271.00 frames. utt_duration=615.7 frames, utt_pad_proportion=0.02119, over 119.00 utterances.], tot_loss[loss=0.8913, simple_loss_common=0.5808, pruned_loss_common=0.2317, simple_loss_rich=0.3729, pruned_loss_rich=0.1827, over 18271.00 frames. utt_duration=615.7 frames, utt_pad_proportion=0.02119, over 119.00 utterances.], batch size: 119, lr: 1.56e-03
2023-08-27 11:29:10,300 INFO [train_noCtc.py:878] (2/4) Epoch 26, batch 0, loss[loss=0.7468, simple_loss_common=0.5088, pruned_loss_common=0.1897, simple_loss_rich=0.3165, pruned_loss_rich=0.1445, over 18295.00 frames. utt_duration=1047 frames, utt_pad_proportion=0.02253, over 70.00 utterances.], tot_loss[loss=0.7468, simple_loss_common=0.5088, pruned_loss_common=0.1897, simple_loss_rich=0.3165, pruned_loss_rich=0.1445, over 18295.00 frames. utt_duration=1047 frames, utt_pad_proportion=0.02253, over 70.00 utterances.], batch size: 70, lr: 1.56e-03
2023-08-27 11:29:10,302 INFO [train_noCtc.py:878] (1/4) Epoch 26, batch 0, loss[loss=0.7697, simple_loss_common=0.5295, pruned_loss_common=0.1908, simple_loss_rich=0.3325, pruned_loss_rich=0.148, over 18281.00 frames. utt_duration=938.8 frames, utt_pad_proportion=0.01592, over 78.00 utterances.], tot_loss[loss=0.7697, simple_loss_common=0.5295, pruned_loss_common=0.1908, simple_loss_rich=0.3325, pruned_loss_rich=0.148, over 18281.00 frames. utt_duration=938.8 frames, utt_pad_proportion=0.01592, over 78.00 utterances.], batch size: 78, lr: 1.56e-03
2023-08-27 11:30:24,506 INFO [train_noCtc.py:878] (3/4) Epoch 26, batch 50, loss[loss=0.6596, simple_loss_common=0.4906, pruned_loss_common=0.1352, simple_loss_rich=0.3228, pruned_loss_rich=0.1176, over 18233.00 frames. utt_duration=745.8 frames, utt_pad_proportion=0.0161, over 98.00 utterances.], tot_loss[loss=0.7122, simple_loss_common=0.4861, pruned_loss_common=0.1658, simple_loss_rich=0.3269, pruned_loss_rich=0.1399, over 807554.96 frames. utt_duration=537.9 frames, utt_pad_proportion=0.0627, over 6021.90 utterances.], batch size: 98, lr: 1.56e-03
2023-08-27 11:30:24,507 INFO [train_noCtc.py:878] (2/4) Epoch 26, batch 50, loss[loss=0.7177, simple_loss_common=0.5009, pruned_loss_common=0.1649, simple_loss_rich=0.3346, pruned_loss_rich=0.135, over 18132.00 frames. utt_duration=527 frames, utt_pad_proportion=0.02776, over 138.00 utterances.], tot_loss[loss=0.7466, simple_loss_common=0.4978, pruned_loss_common=0.1795, simple_loss_rich=0.3361, pruned_loss_rich=0.1502, over 801989.64 frames. utt_duration=458.7 frames, utt_pad_proportion=0.06911, over 7016.17 utterances.], batch size: 138, lr: 1.56e-03
2023-08-27 11:30:24,508 INFO [train_noCtc.py:878] (0/4) Epoch 26, batch 50, loss[loss=0.906, simple_loss_common=0.4867, pruned_loss_common=0.257, simple_loss_rich=0.3692, pruned_loss_rich=0.2211, over 16173.00 frames. utt_duration=191.8 frames, utt_pad_proportion=0.1282, over 340.00 utterances.], tot_loss[loss=0.7288, simple_loss_common=0.4938, pruned_loss_common=0.1728, simple_loss_rich=0.3311, pruned_loss_rich=0.1435, over 806912.34 frames. utt_duration=513 frames, utt_pad_proportion=0.05761, over 6309.75 utterances.], batch size: 340, lr: 1.56e-03
2023-08-27 11:30:24,508 INFO [train_noCtc.py:878] (1/4) Epoch 26, batch 50, loss[loss=0.7382, simple_loss_common=0.4916, pruned_loss_common=0.1751, simple_loss_rich=0.3366, pruned_loss_rich=0.149, over 17712.00 frames. utt_duration=415.6 frames, utt_pad_proportion=0.04682, over 171.00 utterances.], tot_loss[loss=0.7191, simple_loss_common=0.4923, pruned_loss_common=0.1671, simple_loss_rich=0.3303, pruned_loss_rich=0.1407, over 808273.56 frames. utt_duration=517.5 frames, utt_pad_proportion=0.06258, over 6266.14 utterances.], batch size: 171, lr: 1.56e-03
2023-08-27 11:31:39,794 INFO [train_noCtc.py:878] (3/4) Epoch 26, batch 100, loss[loss=0.7298, simple_loss_common=0.5044, pruned_loss_common=0.1696, simple_loss_rich=0.3342, pruned_loss_rich=0.1409, over 18289.00 frames. utt_duration=616.1 frames, utt_pad_proportion=0.02049, over 119.00 utterances.], tot_loss[loss=0.7309, simple_loss_common=0.4928, pruned_loss_common=0.1731, simple_loss_rich=0.3323, pruned_loss_rich=0.1452, over 1413915.52 frames. utt_duration=480.5 frames, utt_pad_proportion=0.07191, over 11805.82 utterances.], batch size: 119, lr: 1.55e-03
2023-08-27 11:31:39,795 INFO [train_noCtc.py:878] (1/4) Epoch 26, batch 100, loss[loss=0.6417, simple_loss_common=0.4842, pruned_loss_common=0.1352, simple_loss_rich=0.3067, pruned_loss_rich=0.1111, over 18252.00 frames. utt_duration=850.5 frames, utt_pad_proportion=0.01562, over 86.00 utterances.], tot_loss[loss=0.7229, simple_loss_common=0.4951, pruned_loss_common=0.1683, simple_loss_rich=0.3317, pruned_loss_rich=0.1412, over 1425685.98 frames. utt_duration=526.4 frames, utt_pad_proportion=0.05702, over 10863.90 utterances.], batch size: 86, lr: 1.55e-03
2023-08-27 11:31:39,796 INFO [train_noCtc.py:878] (2/4) Epoch 26, batch 100, loss[loss=0.7662, simple_loss_common=0.5235, pruned_loss_common=0.1834, simple_loss_rich=0.3454, pruned_loss_rich=0.1484, over 18240.00 frames. utt_duration=670.8 frames, utt_pad_proportion=0.01792, over 109.00 utterances.], tot_loss[loss=0.733, simple_loss_common=0.4948, pruned_loss_common=0.1739, simple_loss_rich=0.3326, pruned_loss_rich=0.1454, over 1417445.51 frames. utt_duration=488.9 frames, utt_pad_proportion=0.06711, over 11631.16 utterances.], batch size: 109, lr: 1.55e-03
2023-08-27 11:31:39,798 INFO [train_noCtc.py:878] (0/4) Epoch 26, batch 100, loss[loss=0.7492, simple_loss_common=0.4936, pruned_loss_common=0.1756, simple_loss_rich=0.343, pruned_loss_rich=0.1553, over 17739.00 frames. utt_duration=375.1 frames, utt_pad_proportion=0.04792, over 190.00 utterances.], tot_loss[loss=0.7277, simple_loss_common=0.4934, pruned_loss_common=0.1714, simple_loss_rich=0.3315, pruned_loss_rich=0.1439, over 1415327.48 frames. utt_duration=481.9 frames, utt_pad_proportion=0.06853, over 11784.90 utterances.], batch size: 190, lr: 1.55e-03
2023-08-27 11:32:49,605 INFO [train_noCtc.py:878] (3/4) Epoch 26, batch 150, loss[loss=0.8076, simple_loss_common=0.5413, pruned_loss_common=0.1993, simple_loss_rich=0.3531, pruned_loss_rich=0.1611, over 18281.00 frames. utt_duration=642.9 frames, utt_pad_proportion=0.02147, over 114.00 utterances.], tot_loss[loss=0.7394, simple_loss_common=0.4982, pruned_loss_common=0.1765, simple_loss_rich=0.334, pruned_loss_rich=0.1468, over 1896738.81 frames. utt_duration=497.8 frames, utt_pad_proportion=0.06453, over 15286.53 utterances.], batch size: 114, lr: 1.55e-03
2023-08-27 11:32:49,606 INFO [train_noCtc.py:878] (1/4) Epoch 26, batch 150, loss[loss=0.6632, simple_loss_common=0.484, pruned_loss_common=0.1418, simple_loss_rich=0.3177, pruned_loss_rich=0.1206, over 18281.00 frames. utt_duration=938.8 frames, utt_pad_proportion=0.01493, over 78.00 utterances.], tot_loss[loss=0.7293, simple_loss_common=0.4963, pruned_loss_common=0.1712, simple_loss_rich=0.3326, pruned_loss_rich=0.1437, over 1895741.98 frames. utt_duration=500.4 frames, utt_pad_proportion=0.07321, over 15198.57 utterances.], batch size: 78, lr: 1.55e-03
2023-08-27 11:32:49,606 INFO [train_noCtc.py:878] (2/4) Epoch 26, batch 150, loss[loss=0.7735, simple_loss_common=0.4875, pruned_loss_common=0.1908, simple_loss_rich=0.3433, pruned_loss_rich=0.1672, over 17532.00 frames. utt_duration=332.2 frames, utt_pad_proportion=0.05882, over 212.00 utterances.], tot_loss[loss=0.7382, simple_loss_common=0.4978, pruned_loss_common=0.1763, simple_loss_rich=0.3332, pruned_loss_rich=0.1464, over 1902639.53 frames. utt_duration=517.6 frames, utt_pad_proportion=0.05704, over 14747.23 utterances.], batch size: 212, lr: 1.55e-03
2023-08-27 11:32:49,606 INFO [train_noCtc.py:878] (0/4) Epoch 26, batch 150, loss[loss=0.8337, simple_loss_common=0.526, pruned_loss_common=0.2112, simple_loss_rich=0.3602, pruned_loss_rich=0.1794, over 17652.00 frames. utt_duration=373 frames, utt_pad_proportion=0.05077, over 190.00 utterances.], tot_loss[loss=0.7396, simple_loss_common=0.4962, pruned_loss_common=0.1766, simple_loss_rich=0.3339, pruned_loss_rich=0.148, over 1885885.79 frames. utt_duration=467.9 frames, utt_pad_proportion=0.07713, over 16174.37 utterances.], batch size: 190, lr: 1.55e-03
2023-08-27 11:33:31,803 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-26.pt
2023-08-27 11:33:51,665 INFO [train_noCtc.py:878] (3/4) Epoch 27, batch 0, loss[loss=0.7703, simple_loss_common=0.5286, pruned_loss_common=0.1917, simple_loss_rich=0.3382, pruned_loss_rich=0.1452, over 18255.00 frames. utt_duration=850.6 frames, utt_pad_proportion=0.01439, over 86.00 utterances.], tot_loss[loss=0.7703, simple_loss_common=0.5286, pruned_loss_common=0.1917, simple_loss_rich=0.3382, pruned_loss_rich=0.1452, over 18255.00 frames. utt_duration=850.6 frames, utt_pad_proportion=0.01439, over 86.00 utterances.], batch size: 86, lr: 1.52e-03
2023-08-27 11:33:51,668 INFO [train_noCtc.py:878] (2/4) Epoch 27, batch 0, loss[loss=0.7886, simple_loss_common=0.4971, pruned_loss_common=0.2009, simple_loss_rich=0.3406, pruned_loss_rich=0.1689, over 17824.00 frames. utt_duration=415.7 frames, utt_pad_proportion=0.04648, over 172.00 utterances.], tot_loss[loss=0.7886, simple_loss_common=0.4971, pruned_loss_common=0.2009, simple_loss_rich=0.3406, pruned_loss_rich=0.1689, over 17824.00 frames. utt_duration=415.7 frames, utt_pad_proportion=0.04648, over 172.00 utterances.], batch size: 172, lr: 1.52e-03
2023-08-27 11:33:51,669 INFO [train_noCtc.py:878] (0/4) Epoch 27, batch 0, loss[loss=0.6968, simple_loss_common=0.4978, pruned_loss_common=0.1598, simple_loss_rich=0.3207, pruned_loss_rich=0.1278, over 18417.00 frames. utt_duration=911 frames, utt_pad_proportion=0.01406, over 81.00 utterances.], tot_loss[loss=0.6968, simple_loss_common=0.4978, pruned_loss_common=0.1598, simple_loss_rich=0.3207, pruned_loss_rich=0.1278, over 18417.00 frames. utt_duration=911 frames, utt_pad_proportion=0.01406, over 81.00 utterances.], batch size: 81, lr: 1.52e-03
2023-08-27 11:33:51,669 INFO [train_noCtc.py:878] (1/4) Epoch 27, batch 0, loss[loss=0.6544, simple_loss_common=0.4439, pruned_loss_common=0.1594, simple_loss_rich=0.2925, pruned_loss_rich=0.1268, over 18026.00 frames. utt_duration=1164 frames, utt_pad_proportion=0.02961, over 62.00 utterances.], tot_loss[loss=0.6544, simple_loss_common=0.4439, pruned_loss_common=0.1594, simple_loss_rich=0.2925, pruned_loss_rich=0.1268, over 18026.00 frames. utt_duration=1164 frames, utt_pad_proportion=0.02961, over 62.00 utterances.], batch size: 62, lr: 1.52e-03
2023-08-27 11:35:05,463 INFO [train_noCtc.py:878] (1/4) Epoch 27, batch 50, loss[loss=0.7747, simple_loss_common=0.4965, pruned_loss_common=0.1944, simple_loss_rich=0.339, pruned_loss_rich=0.1625, over 17503.00 frames. utt_duration=333.3 frames, utt_pad_proportion=0.05838, over 211.00 utterances.], tot_loss[loss=0.7339, simple_loss_common=0.492, pruned_loss_common=0.1768, simple_loss_rich=0.3296, pruned_loss_rich=0.1464, over 803742.32 frames. utt_duration=492.5 frames, utt_pad_proportion=0.06575, over 6547.78 utterances.], batch size: 211, lr: 1.52e-03
2023-08-27 11:35:05,465 INFO [train_noCtc.py:878] (0/4) Epoch 27, batch 50, loss[loss=0.5576, simple_loss_common=0.435, pruned_loss_common=0.1063, simple_loss_rich=0.2844, pruned_loss_rich=0.09163, over 18419.00 frames. utt_duration=1011 frames, utt_pad_proportion=0.01599, over 73.00 utterances.], tot_loss[loss=0.7429, simple_loss_common=0.4999, pruned_loss_common=0.1768, simple_loss_rich=0.3359, pruned_loss_rich=0.1482, over 803601.64 frames. utt_duration=474.1 frames, utt_pad_proportion=0.07566, over 6801.35 utterances.], batch size: 73, lr: 1.52e-03
2023-08-27 11:35:05,465 INFO [train_noCtc.py:878] (3/4) Epoch 27, batch 50, loss[loss=0.9584, simple_loss_common=0.5059, pruned_loss_common=0.2804, simple_loss_rich=0.3793, pruned_loss_rich=0.2354, over 16169.00 frames. utt_duration=192.3 frames, utt_pad_proportion=0.1299, over 339.00 utterances.], tot_loss[loss=0.7571, simple_loss_common=0.4996, pruned_loss_common=0.1844, simple_loss_rich=0.3374, pruned_loss_rich=0.1542, over 797064.73 frames. utt_duration=438.9 frames, utt_pad_proportion=0.08526, over 7288.97 utterances.], batch size: 339, lr: 1.52e-03
2023-08-27 11:35:05,467 INFO [train_noCtc.py:878] (2/4) Epoch 27, batch 50, loss[loss=0.7699, simple_loss_common=0.4919, pruned_loss_common=0.1934, simple_loss_rich=0.3372, pruned_loss_rich=0.162, over 17564.00 frames. utt_duration=332.8 frames, utt_pad_proportion=0.05983, over 212.00 utterances.], tot_loss[loss=0.7347, simple_loss_common=0.4927, pruned_loss_common=0.1762, simple_loss_rich=0.331, pruned_loss_rich=0.1466, over 801861.82 frames. utt_duration=466.9 frames, utt_pad_proportion=0.07541, over 6891.91 utterances.], batch size: 212, lr: 1.52e-03
2023-08-27 11:36:18,917 INFO [train_noCtc.py:878] (3/4) Epoch 27, batch 100, loss[loss=0.7648, simple_loss_common=0.5277, pruned_loss_common=0.1766, simple_loss_rich=0.3531, pruned_loss_rich=0.1478, over 18276.00 frames. utt_duration=615.7 frames, utt_pad_proportion=0.02115, over 119.00 utterances.], tot_loss[loss=0.7437, simple_loss_common=0.4967, pruned_loss_common=0.1799, simple_loss_rich=0.3334, pruned_loss_rich=0.1488, over 1412849.90 frames. utt_duration=475.3 frames, utt_pad_proportion=0.07437, over 11926.23 utterances.], batch size: 119, lr: 1.51e-03
2023-08-27 11:36:18,918 INFO [train_noCtc.py:878] (1/4) Epoch 27, batch 100, loss[loss=0.7546, simple_loss_common=0.5023, pruned_loss_common=0.1778, simple_loss_rich=0.3487, pruned_loss_rich=0.1514, over 18289.00 frames. utt_duration=616.2 frames, utt_pad_proportion=0.02039, over 119.00 utterances.], tot_loss[loss=0.7374, simple_loss_common=0.4955, pruned_loss_common=0.1774, simple_loss_rich=0.3317, pruned_loss_rich=0.1463, over 1418351.07 frames. utt_duration=506 frames, utt_pad_proportion=0.06398, over 11245.04 utterances.], batch size: 119, lr: 1.51e-03
2023-08-27 11:36:18,918 INFO [train_noCtc.py:878] (2/4) Epoch 27, batch 100, loss[loss=0.7745, simple_loss_common=0.506, pruned_loss_common=0.1835, simple_loss_rich=0.3511, pruned_loss_rich=0.1624, over 17701.00 frames. utt_duration=415.6 frames, utt_pad_proportion=0.04689, over 171.00 utterances.], tot_loss[loss=0.734, simple_loss_common=0.4931, pruned_loss_common=0.1767, simple_loss_rich=0.3304, pruned_loss_rich=0.1455, over 1418876.58 frames. utt_duration=497.5 frames, utt_pad_proportion=0.06622, over 11441.02 utterances.], batch size: 171, lr: 1.51e-03
2023-08-27 11:36:18,919 INFO [train_noCtc.py:878] (0/4) Epoch 27, batch 100, loss[loss=0.8188, simple_loss_common=0.4592, pruned_loss_common=0.2013, simple_loss_rich=0.3702, pruned_loss_rich=0.2028, over 14708.00 frames. utt_duration=130.2 frames, utt_pad_proportion=0.2058, over 457.00 utterances.], tot_loss[loss=0.7326, simple_loss_common=0.4974, pruned_loss_common=0.1737, simple_loss_rich=0.3322, pruned_loss_rich=0.144, over 1421357.70 frames. utt_duration=517.1 frames, utt_pad_proportion=0.06642, over 11027.24 utterances.], batch size: 457, lr: 1.51e-03
2023-08-27 11:37:27,375 INFO [train_noCtc.py:878] (3/4) Epoch 27, batch 150, loss[loss=0.7703, simple_loss_common=0.528, pruned_loss_common=0.1836, simple_loss_rich=0.3484, pruned_loss_rich=0.1485, over 18154.00 frames. utt_duration=587 frames, utt_pad_proportion=0.02493, over 124.00 utterances.], tot_loss[loss=0.7371, simple_loss_common=0.4962, pruned_loss_common=0.1764, simple_loss_rich=0.3327, pruned_loss_rich=0.1463, over 1892983.56 frames. utt_duration=486.7 frames, utt_pad_proportion=0.06695, over 15605.71 utterances.], batch size: 124, lr: 1.51e-03
2023-08-27 11:37:27,376 INFO [train_noCtc.py:878] (1/4) Epoch 27, batch 150, loss[loss=0.7093, simple_loss_common=0.502, pruned_loss_common=0.1661, simple_loss_rich=0.3171, pruned_loss_rich=0.1337, over 18207.00 frames. utt_duration=972.6 frames, utt_pad_proportion=0.02053, over 75.00 utterances.], tot_loss[loss=0.7329, simple_loss_common=0.4957, pruned_loss_common=0.1746, simple_loss_rich=0.3314, pruned_loss_rich=0.1448, over 1896614.52 frames. utt_duration=506.9 frames, utt_pad_proportion=0.06353, over 15011.15 utterances.], batch size: 75, lr: 1.51e-03
2023-08-27 11:37:27,376 INFO [train_noCtc.py:878] (0/4) Epoch 27, batch 150, loss[loss=0.6979, simple_loss_common=0.5094, pruned_loss_common=0.1499, simple_loss_rich=0.3317, pruned_loss_rich=0.1275, over 18229.00 frames. utt_duration=849.5 frames, utt_pad_proportion=0.01684, over 86.00 utterances.], tot_loss[loss=0.7281, simple_loss_common=0.4954, pruned_loss_common=0.1717, simple_loss_rich=0.3316, pruned_loss_rich=0.1429, over 1897575.60 frames. utt_duration=503.4 frames, utt_pad_proportion=0.06758, over 15122.67 utterances.], batch size: 86, lr: 1.51e-03
2023-08-27 11:37:27,377 INFO [train_noCtc.py:878] (2/4) Epoch 27, batch 150, loss[loss=0.7778, simple_loss_common=0.517, pruned_loss_common=0.1877, simple_loss_rich=0.3507, pruned_loss_rich=0.1563, over 18258.00 frames. utt_duration=615.2 frames, utt_pad_proportion=0.02196, over 119.00 utterances.], tot_loss[loss=0.7264, simple_loss_common=0.4915, pruned_loss_common=0.1727, simple_loss_rich=0.3294, pruned_loss_rich=0.1432, over 1895454.99 frames. utt_duration=498.2 frames, utt_pad_proportion=0.06942, over 15263.07 utterances.], batch size: 119, lr: 1.51e-03
2023-08-27 11:38:09,728 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-27.pt
2023-08-27 11:38:29,241 INFO [train_noCtc.py:878] (3/4) Epoch 28, batch 0, loss[loss=0.7221, simple_loss_common=0.4893, pruned_loss_common=0.1702, simple_loss_rich=0.3303, pruned_loss_rich=0.1421, over 18043.00 frames. utt_duration=492.4 frames, utt_pad_proportion=0.03256, over 147.00 utterances.], tot_loss[loss=0.7221, simple_loss_common=0.4893, pruned_loss_common=0.1702, simple_loss_rich=0.3303, pruned_loss_rich=0.1421, over 18043.00 frames. utt_duration=492.4 frames, utt_pad_proportion=0.03256, over 147.00 utterances.], batch size: 147, lr: 1.48e-03
2023-08-27 11:38:29,243 INFO [train_noCtc.py:878] (2/4) Epoch 28, batch 0, loss[loss=0.6157, simple_loss_common=0.4597, pruned_loss_common=0.1279, simple_loss_rich=0.3036, pruned_loss_rich=0.1062, over 18238.00 frames. utt_duration=880.4 frames, utt_pad_proportion=0.01636, over 83.00 utterances.], tot_loss[loss=0.6157, simple_loss_common=0.4597, pruned_loss_common=0.1279, simple_loss_rich=0.3036, pruned_loss_rich=0.1062, over 18238.00 frames. utt_duration=880.4 frames, utt_pad_proportion=0.01636, over 83.00 utterances.], batch size: 83, lr: 1.48e-03
2023-08-27 11:38:29,243 INFO [train_noCtc.py:878] (1/4) Epoch 28, batch 0, loss[loss=0.6535, simple_loss_common=0.4757, pruned_loss_common=0.1344, simple_loss_rich=0.3221, pruned_loss_rich=0.1202, over 18349.00 frames. utt_duration=694 frames, utt_pad_proportion=0.01835, over 106.00 utterances.], tot_loss[loss=0.6535, simple_loss_common=0.4757, pruned_loss_common=0.1344, simple_loss_rich=0.3221, pruned_loss_rich=0.1202, over 18349.00 frames. utt_duration=694 frames, utt_pad_proportion=0.01835, over 106.00 utterances.], batch size: 106, lr: 1.48e-03
2023-08-27 11:38:29,245 INFO [train_noCtc.py:878] (0/4) Epoch 28, batch 0, loss[loss=0.6494, simple_loss_common=0.4705, pruned_loss_common=0.1391, simple_loss_rich=0.3133, pruned_loss_rich=0.1184, over 18355.00 frames. utt_duration=826.1 frames, utt_pad_proportion=0.0142, over 89.00 utterances.], tot_loss[loss=0.6494, simple_loss_common=0.4705, pruned_loss_common=0.1391, simple_loss_rich=0.3133, pruned_loss_rich=0.1184, over 18355.00 frames. utt_duration=826.1 frames, utt_pad_proportion=0.0142, over 89.00 utterances.], batch size: 89, lr: 1.48e-03
2023-08-27 11:39:40,680 INFO [train_noCtc.py:878] (3/4) Epoch 28, batch 50, loss[loss=0.7731, simple_loss_common=0.55, pruned_loss_common=0.1839, simple_loss_rich=0.3461, pruned_loss_rich=0.1412, over 18174.00 frames. utt_duration=587.7 frames, utt_pad_proportion=0.02374, over 124.00 utterances.], tot_loss[loss=0.691, simple_loss_common=0.4774, pruned_loss_common=0.1573, simple_loss_rich=0.3225, pruned_loss_rich=0.1337, over 803123.37 frames. utt_duration=487 frames, utt_pad_proportion=0.07319, over 6616.36 utterances.], batch size: 124, lr: 1.48e-03
2023-08-27 11:39:40,682 INFO [train_noCtc.py:878] (1/4) Epoch 28, batch 50, loss[loss=0.7963, simple_loss_common=0.5431, pruned_loss_common=0.1933, simple_loss_rich=0.352, pruned_loss_rich=0.1555, over 18041.00 frames. utt_duration=492.3 frames, utt_pad_proportion=0.03273, over 147.00 utterances.], tot_loss[loss=0.6921, simple_loss_common=0.4813, pruned_loss_common=0.1574, simple_loss_rich=0.3224, pruned_loss_rich=0.1328, over 808702.29 frames. utt_duration=543.1 frames, utt_pad_proportion=0.05477, over 5972.37 utterances.], batch size: 147, lr: 1.48e-03
2023-08-27 11:39:40,683 INFO [train_noCtc.py:878] (2/4) Epoch 28, batch 50, loss[loss=0.7876, simple_loss_common=0.5486, pruned_loss_common=0.1866, simple_loss_rich=0.3558, pruned_loss_rich=0.1487, over 18375.00 frames. utt_duration=694.9 frames, utt_pad_proportion=0.01713, over 106.00 utterances.], tot_loss[loss=0.72, simple_loss_common=0.4863, pruned_loss_common=0.1694, simple_loss_rich=0.3297, pruned_loss_rich=0.1426, over 798724.45 frames. utt_duration=443.7 frames, utt_pad_proportion=0.07772, over 7225.00 utterances.], batch size: 106, lr: 1.48e-03
2023-08-27 11:39:40,816 INFO [train_noCtc.py:878] (0/4) Epoch 28, batch 50, loss[loss=0.9131, simple_loss_common=0.5435, pruned_loss_common=0.252, simple_loss_rich=0.3709, pruned_loss_rich=0.2038, over 16908.00 frames. utt_duration=244.7 frames, utt_pad_proportion=0.09021, over 278.00 utterances.], tot_loss[loss=0.7066, simple_loss_common=0.4868, pruned_loss_common=0.1618, simple_loss_rich=0.3278, pruned_loss_rich=0.1374, over 805935.98 frames. utt_duration=487.6 frames, utt_pad_proportion=0.06478, over 6631.90 utterances.], batch size: 278, lr: 1.48e-03
2023-08-27 11:40:51,108 INFO [train_noCtc.py:878] (3/4) Epoch 28, batch 100, loss[loss=0.9655, simple_loss_common=0.5676, pruned_loss_common=0.2678, simple_loss_rich=0.3942, pruned_loss_rich=0.2167, over 16869.00 frames. utt_duration=244.2 frames, utt_pad_proportion=0.09211, over 278.00 utterances.], tot_loss[loss=0.7082, simple_loss_common=0.4865, pruned_loss_common=0.1636, simple_loss_rich=0.3267, pruned_loss_rich=0.138, over 1414459.48 frames. utt_duration=482.8 frames, utt_pad_proportion=0.07567, over 11755.18 utterances.], batch size: 278, lr: 1.48e-03
2023-08-27 11:40:51,109 INFO [train_noCtc.py:878] (0/4) Epoch 28, batch 100, loss[loss=0.7756, simple_loss_common=0.5465, pruned_loss_common=0.1884, simple_loss_rich=0.3404, pruned_loss_rich=0.1437, over 18337.00 frames. utt_duration=720.6 frames, utt_pad_proportion=0.01687, over 102.00 utterances.], tot_loss[loss=0.7114, simple_loss_common=0.4906, pruned_loss_common=0.1645, simple_loss_rich=0.3278, pruned_loss_rich=0.1377, over 1420810.53 frames. utt_duration=499.9 frames, utt_pad_proportion=0.06561, over 11403.25 utterances.], batch size: 102, lr: 1.48e-03
2023-08-27 11:40:51,110 INFO [train_noCtc.py:878] (1/4) Epoch 28, batch 100, loss[loss=0.7557, simple_loss_common=0.5445, pruned_loss_common=0.1758, simple_loss_rich=0.3429, pruned_loss_rich=0.1362, over 18246.00 frames. utt_duration=850.1 frames, utt_pad_proportion=0.01608, over 86.00 utterances.], tot_loss[loss=0.7075, simple_loss_common=0.4857, pruned_loss_common=0.1647, simple_loss_rich=0.3249, pruned_loss_rich=0.1375, over 1422353.89 frames. utt_duration=527.3 frames, utt_pad_proportion=0.0576, over 10820.60 utterances.], batch size: 86, lr: 1.48e-03
2023-08-27 11:40:51,110 INFO [train_noCtc.py:878] (2/4) Epoch 28, batch 100, loss[loss=0.8554, simple_loss_common=0.5587, pruned_loss_common=0.2151, simple_loss_rich=0.3704, pruned_loss_rich=0.1757, over 17664.00 frames. utt_duration=373.4 frames, utt_pad_proportion=0.05239, over 190.00 utterances.], tot_loss[loss=0.727, simple_loss_common=0.4918, pruned_loss_common=0.1721, simple_loss_rich=0.3305, pruned_loss_rich=0.1438, over 1413481.00 frames. utt_duration=469.1 frames, utt_pad_proportion=0.06946, over 12090.55 utterances.], batch size: 190, lr: 1.48e-03
2023-08-27 11:41:58,422 INFO [train_noCtc.py:878] (3/4) Epoch 28, batch 150, loss[loss=0.6761, simple_loss_common=0.479, pruned_loss_common=0.1567, simple_loss_rich=0.3102, pruned_loss_rich=0.1248, over 18229.00 frames. utt_duration=973.7 frames, utt_pad_proportion=0.01841, over 75.00 utterances.], tot_loss[loss=0.706, simple_loss_common=0.4878, pruned_loss_common=0.1633, simple_loss_rich=0.3251, pruned_loss_rich=0.1363, over 1898188.29 frames. utt_duration=521.8 frames, utt_pad_proportion=0.0685, over 14592.18 utterances.], batch size: 75, lr: 1.47e-03
2023-08-27 11:41:58,423 INFO [train_noCtc.py:878] (1/4) Epoch 28, batch 150, loss[loss=0.6416, simple_loss_common=0.464, pruned_loss_common=0.1423, simple_loss_rich=0.3011, pruned_loss_rich=0.1168, over 18346.00 frames. utt_duration=1050 frames, utt_pad_proportion=0.01987, over 70.00 utterances.], tot_loss[loss=0.7096, simple_loss_common=0.4866, pruned_loss_common=0.1656, simple_loss_rich=0.325, pruned_loss_rich=0.1381, over 1895385.77 frames. utt_duration=510.4 frames, utt_pad_proportion=0.06715, over 14896.86 utterances.], batch size: 70, lr: 1.47e-03
2023-08-27 11:41:58,425 INFO [train_noCtc.py:878] (2/4) Epoch 28, batch 150, loss[loss=0.751, simple_loss_common=0.5185, pruned_loss_common=0.1774, simple_loss_rich=0.341, pruned_loss_rich=0.1438, over 18220.00 frames. utt_duration=613.8 frames, utt_pad_proportion=0.02413, over 119.00 utterances.], tot_loss[loss=0.7278, simple_loss_common=0.4954, pruned_loss_common=0.1718, simple_loss_rich=0.3312, pruned_loss_rich=0.1427, over 1894946.43 frames. utt_duration=489.6 frames, utt_pad_proportion=0.06723, over 15527.80 utterances.], batch size: 119, lr: 1.47e-03
2023-08-27 11:41:58,555 INFO [train_noCtc.py:878] (0/4) Epoch 28, batch 150, loss[loss=0.6465, simple_loss_common=0.4668, pruned_loss_common=0.1444, simple_loss_rich=0.3047, pruned_loss_rich=0.1164, over 18295.00 frames. utt_duration=939.8 frames, utt_pad_proportion=0.01484, over 78.00 utterances.], tot_loss[loss=0.715, simple_loss_common=0.4916, pruned_loss_common=0.1663, simple_loss_rich=0.3285, pruned_loss_rich=0.1386, over 1896473.29 frames. utt_duration=497.3 frames, utt_pad_proportion=0.06648, over 15299.67 utterances.], batch size: 78, lr: 1.47e-03
2023-08-27 11:42:40,252 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-28.pt
2023-08-27 11:43:00,639 INFO [train_noCtc.py:878] (0/4) Epoch 29, batch 0, loss[loss=0.7663, simple_loss_common=0.4821, pruned_loss_common=0.189, simple_loss_rich=0.3375, pruned_loss_rich=0.1676, over 17400.00 frames. utt_duration=290.2 frames, utt_pad_proportion=0.06374, over 241.00 utterances.], tot_loss[loss=0.7663, simple_loss_common=0.4821, pruned_loss_common=0.189, simple_loss_rich=0.3375, pruned_loss_rich=0.1676, over 17400.00 frames. utt_duration=290.2 frames, utt_pad_proportion=0.06374, over 241.00 utterances.], batch size: 241, lr: 1.45e-03
2023-08-27 11:43:00,639 INFO [train_noCtc.py:878] (3/4) Epoch 29, batch 0, loss[loss=0.6645, simple_loss_common=0.4955, pruned_loss_common=0.1427, simple_loss_rich=0.3127, pruned_loss_rich=0.1177, over 18243.00 frames. utt_duration=746.1 frames, utt_pad_proportion=0.01697, over 98.00 utterances.], tot_loss[loss=0.6645, simple_loss_common=0.4955, pruned_loss_common=0.1427, simple_loss_rich=0.3127, pruned_loss_rich=0.1177, over 18243.00 frames. utt_duration=746.1 frames, utt_pad_proportion=0.01697, over 98.00 utterances.], batch size: 98, lr: 1.45e-03
2023-08-27 11:43:00,639 INFO [train_noCtc.py:878] (1/4) Epoch 29, batch 0, loss[loss=0.6134, simple_loss_common=0.4621, pruned_loss_common=0.1229, simple_loss_rich=0.3037, pruned_loss_rich=0.1076, over 18399.00 frames. utt_duration=910.1 frames, utt_pad_proportion=0.01499, over 81.00 utterances.], tot_loss[loss=0.6134, simple_loss_common=0.4621, pruned_loss_common=0.1229, simple_loss_rich=0.3037, pruned_loss_rich=0.1076, over 18399.00 frames. utt_duration=910.1 frames, utt_pad_proportion=0.01499, over 81.00 utterances.], batch size: 81, lr: 1.45e-03
2023-08-27 11:43:00,640 INFO [train_noCtc.py:878] (2/4) Epoch 29, batch 0, loss[loss=0.7011, simple_loss_common=0.4601, pruned_loss_common=0.1616, simple_loss_rich=0.3217, pruned_loss_rich=0.1486, over 17397.00 frames. utt_duration=331.2 frames, utt_pad_proportion=0.0644, over 211.00 utterances.], tot_loss[loss=0.7011, simple_loss_common=0.4601, pruned_loss_common=0.1616, simple_loss_rich=0.3217, pruned_loss_rich=0.1486, over 17397.00 frames. utt_duration=331.2 frames, utt_pad_proportion=0.0644, over 211.00 utterances.], batch size: 211, lr: 1.45e-03
2023-08-27 11:44:10,890 INFO [train_noCtc.py:878] (3/4) Epoch 29, batch 50, loss[loss=0.7408, simple_loss_common=0.455, pruned_loss_common=0.1874, simple_loss_rich=0.3265, pruned_loss_rich=0.1626, over 16858.00 frames. utt_duration=244.1 frames, utt_pad_proportion=0.0927, over 278.00 utterances.], tot_loss[loss=0.6947, simple_loss_common=0.4801, pruned_loss_common=0.1593, simple_loss_rich=0.3226, pruned_loss_rich=0.1341, over 802019.97 frames. utt_duration=484.4 frames, utt_pad_proportion=0.07325, over 6642.47 utterances.], batch size: 278, lr: 1.44e-03
2023-08-27 11:44:10,891 INFO [train_noCtc.py:878] (0/4) Epoch 29, batch 50, loss[loss=0.5778, simple_loss_common=0.4421, pruned_loss_common=0.1166, simple_loss_rich=0.2881, pruned_loss_rich=0.09605, over 18224.00 frames. utt_duration=745.3 frames, utt_pad_proportion=0.01799, over 98.00 utterances.], tot_loss[loss=0.6866, simple_loss_common=0.4803, pruned_loss_common=0.1564, simple_loss_rich=0.3197, pruned_loss_rich=0.1302, over 810274.57 frames. utt_duration=548.5 frames, utt_pad_proportion=0.05503, over 5925.40 utterances.], batch size: 98, lr: 1.44e-03
2023-08-27 11:44:10,892 INFO [train_noCtc.py:878] (2/4) Epoch 29, batch 50, loss[loss=0.7095, simple_loss_common=0.5274, pruned_loss_common=0.1546, simple_loss_rich=0.3214, pruned_loss_rich=0.1305, over 18046.00 frames. utt_duration=492.5 frames, utt_pad_proportion=0.03244, over 147.00 utterances.], tot_loss[loss=0.7012, simple_loss_common=0.4904, pruned_loss_common=0.1596, simple_loss_rich=0.3263, pruned_loss_rich=0.1333, over 811413.34 frames. utt_duration=535.9 frames, utt_pad_proportion=0.0497, over 6073.09 utterances.], batch size: 147, lr: 1.44e-03
2023-08-27 11:44:10,893 INFO [train_noCtc.py:878] (1/4) Epoch 29, batch 50, loss[loss=0.755, simple_loss_common=0.4273, pruned_loss_common=0.1851, simple_loss_rich=0.345, pruned_loss_rich=0.1837, over 14736.00 frames. utt_duration=130.5 frames, utt_pad_proportion=0.2044, over 457.00 utterances.], tot_loss[loss=0.7059, simple_loss_common=0.4858, pruned_loss_common=0.163, simple_loss_rich=0.3267, pruned_loss_rich=0.1366, over 800931.13 frames. utt_duration=462.7 frames, utt_pad_proportion=0.07816, over 6947.26 utterances.], batch size: 457, lr: 1.44e-03
2023-08-27 11:45:23,689 INFO [train_noCtc.py:878] (3/4) Epoch 29, batch 100, loss[loss=0.6917, simple_loss_common=0.4913, pruned_loss_common=0.1586, simple_loss_rich=0.317, pruned_loss_rich=0.129, over 18192.00 frames. utt_duration=878.3 frames, utt_pad_proportion=0.01755, over 83.00 utterances.], tot_loss[loss=0.7195, simple_loss_common=0.4897, pruned_loss_common=0.1693, simple_loss_rich=0.3289, pruned_loss_rich=0.1409, over 1412933.53 frames. utt_duration=466 frames, utt_pad_proportion=0.06943, over 12166.77 utterances.], batch size: 83, lr: 1.44e-03
2023-08-27 11:45:23,690 INFO [train_noCtc.py:878] (1/4) Epoch 29, batch 100, loss[loss=0.7432, simple_loss_common=0.5267, pruned_loss_common=0.1763, simple_loss_rich=0.3365, pruned_loss_rich=0.1353, over 18084.00 frames. utt_duration=525.7 frames, utt_pad_proportion=0.03001, over 138.00 utterances.], tot_loss[loss=0.7128, simple_loss_common=0.4873, pruned_loss_common=0.1671, simple_loss_rich=0.3265, pruned_loss_rich=0.1388, over 1412696.17 frames. utt_duration=471.2 frames, utt_pad_proportion=0.0754, over 12030.15 utterances.], batch size: 138, lr: 1.44e-03
2023-08-27 11:45:23,691 INFO [train_noCtc.py:878] (2/4) Epoch 29, batch 100, loss[loss=0.5614, simple_loss_common=0.4096, pruned_loss_common=0.1174, simple_loss_rich=0.2729, pruned_loss_rich=0.1027, over 18047.00 frames. utt_duration=1166 frames, utt_pad_proportion=0.02862, over 62.00 utterances.], tot_loss[loss=0.6986, simple_loss_common=0.4859, pruned_loss_common=0.1606, simple_loss_rich=0.3232, pruned_loss_rich=0.1334, over 1423242.34 frames. utt_duration=536.7 frames, utt_pad_proportion=0.06084, over 10636.19 utterances.], batch size: 62, lr: 1.44e-03
2023-08-27 11:45:23,691 INFO [train_noCtc.py:878] (0/4) Epoch 29, batch 100, loss[loss=0.6683, simple_loss_common=0.4865, pruned_loss_common=0.1508, simple_loss_rich=0.3109, pruned_loss_rich=0.1188, over 18238.00 frames. utt_duration=880.4 frames, utt_pad_proportion=0.01522, over 83.00 utterances.], tot_loss[loss=0.6997, simple_loss_common=0.4891, pruned_loss_common=0.1609, simple_loss_rich=0.3237, pruned_loss_rich=0.1325, over 1431436.09 frames. utt_duration=561.3 frames, utt_pad_proportion=0.0491, over 10228.01 utterances.], batch size: 83, lr: 1.44e-03
2023-08-27 11:46:32,804 INFO [train_noCtc.py:878] (3/4) Epoch 29, batch 150, loss[loss=0.8992, simple_loss_common=0.5393, pruned_loss_common=0.2456, simple_loss_rich=0.3678, pruned_loss_rich=0.2, over 17344.00 frames. utt_duration=289.4 frames, utt_pad_proportion=0.06938, over 241.00 utterances.], tot_loss[loss=0.7216, simple_loss_common=0.4905, pruned_loss_common=0.1696, simple_loss_rich=0.3293, pruned_loss_rich=0.1421, over 1881612.17 frames. utt_duration=450 frames, utt_pad_proportion=0.0779, over 16779.18 utterances.], batch size: 241, lr: 1.44e-03
2023-08-27 11:46:32,805 INFO [train_noCtc.py:878] (0/4) Epoch 29, batch 150, loss[loss=0.8786, simple_loss_common=0.5303, pruned_loss_common=0.2412, simple_loss_rich=0.3621, pruned_loss_rich=0.1912, over 17344.00 frames. utt_duration=289.3 frames, utt_pad_proportion=0.06969, over 241.00 utterances.], tot_loss[loss=0.7032, simple_loss_common=0.4872, pruned_loss_common=0.1618, simple_loss_rich=0.3255, pruned_loss_rich=0.1351, over 1899493.06 frames. utt_duration=505.8 frames, utt_pad_proportion=0.06632, over 15066.68 utterances.], batch size: 241, lr: 1.44e-03
2023-08-27 11:46:32,805 INFO [train_noCtc.py:878] (1/4) Epoch 29, batch 150, loss[loss=1.074, simple_loss_common=0.5396, pruned_loss_common=0.3283, simple_loss_rich=0.403, pruned_loss_rich=0.2749, over 16021.00 frames. utt_duration=190.5 frames, utt_pad_proportion=0.1382, over 339.00 utterances.], tot_loss[loss=0.7174, simple_loss_common=0.4869, pruned_loss_common=0.1689, simple_loss_rich=0.3277, pruned_loss_rich=0.1412, over 1880516.18 frames. utt_duration=449.7 frames, utt_pad_proportion=0.08293, over 16781.70 utterances.], batch size: 339, lr: 1.44e-03
2023-08-27 11:46:32,806 INFO [train_noCtc.py:878] (2/4) Epoch 29, batch 150, loss[loss=0.6573, simple_loss_common=0.4586, pruned_loss_common=0.1507, simple_loss_rich=0.3049, pruned_loss_rich=0.1249, over 18036.00 frames. utt_duration=1094 frames, utt_pad_proportion=0.02373, over 66.00 utterances.], tot_loss[loss=0.7027, simple_loss_common=0.4859, pruned_loss_common=0.1624, simple_loss_rich=0.3238, pruned_loss_rich=0.1354, over 1902541.76 frames. utt_duration=529.6 frames, utt_pad_proportion=0.05652, over 14408.95 utterances.], batch size: 66, lr: 1.44e-03
2023-08-27 11:47:15,632 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-29.pt
2023-08-27 11:47:35,351 INFO [train_noCtc.py:878] (3/4) Epoch 30, batch 0, loss[loss=0.8124, simple_loss_common=0.5329, pruned_loss_common=0.1997, simple_loss_rich=0.3478, pruned_loss_rich=0.1724, over 18303.00 frames. utt_duration=797.2 frames, utt_pad_proportion=0.01695, over 92.00 utterances.], tot_loss[loss=0.8124, simple_loss_common=0.5329, pruned_loss_common=0.1997, simple_loss_rich=0.3478, pruned_loss_rich=0.1724, over 18303.00 frames. utt_duration=797.2 frames, utt_pad_proportion=0.01695, over 92.00 utterances.], batch size: 92, lr: 1.41e-03
2023-08-27 11:47:35,351 INFO [train_noCtc.py:878] (1/4) Epoch 30, batch 0, loss[loss=1.007, simple_loss_common=0.5677, pruned_loss_common=0.2853, simple_loss_rich=0.3894, pruned_loss_rich=0.2427, over 17003.00 frames. utt_duration=246.1 frames, utt_pad_proportion=0.08519, over 278.00 utterances.], tot_loss[loss=1.007, simple_loss_common=0.5677, pruned_loss_common=0.2853, simple_loss_rich=0.3894, pruned_loss_rich=0.2427, over 17003.00 frames. utt_duration=246.1 frames, utt_pad_proportion=0.08519, over 278.00 utterances.], batch size: 278, lr: 1.41e-03
2023-08-27 11:47:35,351 INFO [train_noCtc.py:878] (0/4) Epoch 30, batch 0, loss[loss=0.8429, simple_loss_common=0.5471, pruned_loss_common=0.2141, simple_loss_rich=0.3527, pruned_loss_rich=0.1789, over 18230.00 frames. utt_duration=745.6 frames, utt_pad_proportion=0.01767, over 98.00 utterances.], tot_loss[loss=0.8429, simple_loss_common=0.5471, pruned_loss_common=0.2141, simple_loss_rich=0.3527, pruned_loss_rich=0.1789, over 18230.00 frames. utt_duration=745.6 frames, utt_pad_proportion=0.01767, over 98.00 utterances.], batch size: 98, lr: 1.41e-03
2023-08-27 11:47:35,353 INFO [train_noCtc.py:878] (2/4) Epoch 30, batch 0, loss[loss=0.8266, simple_loss_common=0.5338, pruned_loss_common=0.2077, simple_loss_rich=0.3511, pruned_loss_rich=0.1764, over 18174.00 frames. utt_duration=587.6 frames, utt_pad_proportion=0.02386, over 124.00 utterances.], tot_loss[loss=0.8266, simple_loss_common=0.5338, pruned_loss_common=0.2077, simple_loss_rich=0.3511, pruned_loss_rich=0.1764, over 18174.00 frames. utt_duration=587.6 frames, utt_pad_proportion=0.02386, over 124.00 utterances.], batch size: 124, lr: 1.41e-03
2023-08-27 11:48:50,263 INFO [train_noCtc.py:878] (3/4) Epoch 30, batch 50, loss[loss=0.6978, simple_loss_common=0.485, pruned_loss_common=0.1649, simple_loss_rich=0.3244, pruned_loss_rich=0.1281, over 18290.00 frames. utt_duration=616.4 frames, utt_pad_proportion=0.02011, over 119.00 utterances.], tot_loss[loss=0.7085, simple_loss_common=0.4833, pruned_loss_common=0.1664, simple_loss_rich=0.3246, pruned_loss_rich=0.1381, over 799674.11 frames. utt_duration=458.5 frames, utt_pad_proportion=0.08386, over 6998.54 utterances.], batch size: 119, lr: 1.41e-03
2023-08-27 11:48:50,264 INFO [train_noCtc.py:878] (1/4) Epoch 30, batch 50, loss[loss=0.8337, simple_loss_common=0.4989, pruned_loss_common=0.222, simple_loss_rich=0.3555, pruned_loss_rich=0.1845, over 16807.00 frames. utt_duration=243.3 frames, utt_pad_proportion=0.09546, over 278.00 utterances.], tot_loss[loss=0.7061, simple_loss_common=0.4835, pruned_loss_common=0.1653, simple_loss_rich=0.3245, pruned_loss_rich=0.1368, over 806592.78 frames. utt_duration=506.6 frames, utt_pad_proportion=0.06189, over 6386.91 utterances.], batch size: 278, lr: 1.41e-03
2023-08-27 11:48:50,266 INFO [train_noCtc.py:878] (2/4) Epoch 30, batch 50, loss[loss=0.7367, simple_loss_common=0.4792, pruned_loss_common=0.1808, simple_loss_rich=0.3277, pruned_loss_rich=0.1525, over 17626.00 frames. utt_duration=372.6 frames, utt_pad_proportion=0.05434, over 190.00 utterances.], tot_loss[loss=0.7171, simple_loss_common=0.4887, pruned_loss_common=0.1688, simple_loss_rich=0.3283, pruned_loss_rich=0.1398, over 802737.13 frames. utt_duration=471.2 frames, utt_pad_proportion=0.07518, over 6836.17 utterances.], batch size: 190, lr: 1.41e-03
2023-08-27 11:48:50,266 INFO [train_noCtc.py:878] (0/4) Epoch 30, batch 50, loss[loss=0.6825, simple_loss_common=0.4871, pruned_loss_common=0.1582, simple_loss_rich=0.3169, pruned_loss_rich=0.1223, over 18196.00 frames. utt_duration=588.5 frames, utt_pad_proportion=0.02249, over 124.00 utterances.], tot_loss[loss=0.7208, simple_loss_common=0.4904, pruned_loss_common=0.1704, simple_loss_rich=0.329, pruned_loss_rich=0.1406, over 804711.62 frames. utt_duration=482.7 frames, utt_pad_proportion=0.06105, over 6689.67 utterances.], batch size: 124, lr: 1.41e-03
2023-08-27 11:50:03,579 INFO [train_noCtc.py:878] (3/4) Epoch 30, batch 100, loss[loss=0.7051, simple_loss_common=0.5089, pruned_loss_common=0.1517, simple_loss_rich=0.3387, pruned_loss_rich=0.1297, over 18353.00 frames. utt_duration=721.1 frames, utt_pad_proportion=0.01621, over 102.00 utterances.], tot_loss[loss=0.7036, simple_loss_common=0.4835, pruned_loss_common=0.1641, simple_loss_rich=0.3235, pruned_loss_rich=0.136, over 1414882.66 frames. utt_duration=487.9 frames, utt_pad_proportion=0.072, over 11635.05 utterances.], batch size: 102, lr: 1.40e-03
2023-08-27 11:50:03,580 INFO [train_noCtc.py:878] (0/4) Epoch 30, batch 100, loss[loss=0.7308, simple_loss_common=0.4297, pruned_loss_common=0.1746, simple_loss_rich=0.3449, pruned_loss_rich=0.169, over 14863.00 frames. utt_duration=131.6 frames, utt_pad_proportion=0.1974, over 457.00 utterances.], tot_loss[loss=0.7042, simple_loss_common=0.4865, pruned_loss_common=0.1629, simple_loss_rich=0.3256, pruned_loss_rich=0.1353, over 1417928.65 frames. utt_duration=488.9 frames, utt_pad_proportion=0.06603, over 11637.24 utterances.], batch size: 457, lr: 1.40e-03
2023-08-27 11:50:03,581 INFO [train_noCtc.py:878] (2/4) Epoch 30, batch 100, loss[loss=0.6923, simple_loss_common=0.4763, pruned_loss_common=0.1593, simple_loss_rich=0.3214, pruned_loss_rich=0.1341, over 17667.00 frames. utt_duration=373.6 frames, utt_pad_proportion=0.05172, over 190.00 utterances.], tot_loss[loss=0.7085, simple_loss_common=0.4865, pruned_loss_common=0.1648, simple_loss_rich=0.3263, pruned_loss_rich=0.1373, over 1414128.62 frames. utt_duration=478.3 frames, utt_pad_proportion=0.07412, over 11863.65 utterances.], batch size: 190, lr: 1.40e-03
2023-08-27 11:50:03,581 INFO [train_noCtc.py:878] (1/4) Epoch 30, batch 100, loss[loss=0.6718, simple_loss_common=0.5038, pruned_loss_common=0.1399, simple_loss_rich=0.3257, pruned_loss_rich=0.1172, over 18222.00 frames. utt_duration=745.3 frames, utt_pad_proportion=0.01799, over 98.00 utterances.], tot_loss[loss=0.6911, simple_loss_common=0.4808, pruned_loss_common=0.1584, simple_loss_rich=0.3209, pruned_loss_rich=0.1319, over 1425041.73 frames. utt_duration=541.9 frames, utt_pad_proportion=0.05654, over 10547.47 utterances.], batch size: 98, lr: 1.40e-03
2023-08-27 11:51:13,278 INFO [train_noCtc.py:878] (3/4) Epoch 30, batch 150, loss[loss=0.746, simple_loss_common=0.4864, pruned_loss_common=0.1768, simple_loss_rich=0.342, pruned_loss_rich=0.1551, over 17365.00 frames. utt_duration=330.6 frames, utt_pad_proportion=0.06599, over 211.00 utterances.], tot_loss[loss=0.7116, simple_loss_common=0.4865, pruned_loss_common=0.1663, simple_loss_rich=0.327, pruned_loss_rich=0.1386, over 1883760.81 frames. utt_duration=454.6 frames, utt_pad_proportion=0.07654, over 16628.73 utterances.], batch size: 211, lr: 1.40e-03
2023-08-27 11:51:13,280 INFO [train_noCtc.py:878] (0/4) Epoch 30, batch 150, loss[loss=0.7584, simple_loss_common=0.4312, pruned_loss_common=0.1754, simple_loss_rich=0.3561, pruned_loss_rich=0.1893, over 14773.00 frames. utt_duration=130.8 frames, utt_pad_proportion=0.2025, over 457.00 utterances.], tot_loss[loss=0.704, simple_loss_common=0.4846, pruned_loss_common=0.1628, simple_loss_rich=0.3255, pruned_loss_rich=0.1362, over 1889197.98 frames. utt_duration=467.4 frames, utt_pad_proportion=0.07148, over 16220.66 utterances.], batch size: 457, lr: 1.40e-03
2023-08-27 11:51:13,280 INFO [train_noCtc.py:878] (2/4) Epoch 30, batch 150, loss[loss=0.5674, simple_loss_common=0.4231, pruned_loss_common=0.1154, simple_loss_rich=0.2783, pruned_loss_rich=0.1013, over 18408.00 frames. utt_duration=1010 frames, utt_pad_proportion=0.01642, over 73.00 utterances.], tot_loss[loss=0.697, simple_loss_common=0.4847, pruned_loss_common=0.1599, simple_loss_rich=0.3234, pruned_loss_rich=0.1331, over 1902177.83 frames. utt_duration=523.3 frames, utt_pad_proportion=0.06194, over 14580.15 utterances.], batch size: 73, lr: 1.40e-03
2023-08-27 11:51:13,280 INFO [train_noCtc.py:878] (1/4) Epoch 30, batch 150, loss[loss=0.6648, simple_loss_common=0.476, pruned_loss_common=0.1439, simple_loss_rich=0.3182, pruned_loss_rich=0.1238, over 18231.00 frames. utt_duration=670.4 frames, utt_pad_proportion=0.01838, over 109.00 utterances.], tot_loss[loss=0.6886, simple_loss_common=0.4813, pruned_loss_common=0.1564, simple_loss_rich=0.3215, pruned_loss_rich=0.1309, over 1898568.97 frames. utt_duration=517.1 frames, utt_pad_proportion=0.06774, over 14727.93 utterances.], batch size: 109, lr: 1.40e-03
2023-08-27 11:51:55,956 INFO [checkpoint.py:75] (0/4) Saving checkpoint to lstm_transducer_stateless3/exp-ami-scratch-noCtc-cond/epoch-30.pt
2023-08-27 11:51:56,010 INFO [train_noCtc.py:1099] (2/4) Done!
2023-08-27 11:51:56,011 INFO [train_noCtc.py:1099] (1/4) Done!
2023-08-27 11:51:56,055 INFO [train_noCtc.py:1099] (3/4) Done!
2023-08-27 11:51:57,852 INFO [train_noCtc.py:1099] (0/4) Done!
